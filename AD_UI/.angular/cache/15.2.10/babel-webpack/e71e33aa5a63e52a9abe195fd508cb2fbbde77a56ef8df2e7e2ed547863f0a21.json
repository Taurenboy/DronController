{"ast":null,"code":"var _asyncToGenerator = require(\"C:/Users/ingev/Documents/Desarrollo/Luna/DronController/AD_UI/node_modules/@babel/runtime/helpers/asyncToGenerator.js\").default;\nconst sleep = require('../utils/sleep');\nconst websiteUrl = require('../utils/websiteUrl');\nconst arrayDiff = require('../utils/arrayDiff');\nconst createRetry = require('../retry');\nconst sharedPromiseTo = require('../utils/sharedPromiseTo');\nconst OffsetManager = require('./offsetManager');\nconst Batch = require('./batch');\nconst SeekOffsets = require('./seekOffsets');\nconst SubscriptionState = require('./subscriptionState');\nconst {\n  events: {\n    GROUP_JOIN,\n    HEARTBEAT,\n    CONNECT,\n    RECEIVED_UNSUBSCRIBED_TOPICS\n  }\n} = require('./instrumentationEvents');\nconst {\n  MemberAssignment\n} = require('./assignerProtocol');\nconst {\n  KafkaJSError,\n  KafkaJSNonRetriableError,\n  KafkaJSStaleTopicMetadataAssignment,\n  isRebalancing\n} = require('../errors');\nconst {\n  keys\n} = Object;\nconst STALE_METADATA_ERRORS = ['LEADER_NOT_AVAILABLE',\n// Fetch before v9 uses NOT_LEADER_FOR_PARTITION\n'NOT_LEADER_FOR_PARTITION',\n// Fetch after v9 uses {FENCED,UNKNOWN}_LEADER_EPOCH\n'FENCED_LEADER_EPOCH', 'UNKNOWN_LEADER_EPOCH', 'UNKNOWN_TOPIC_OR_PARTITION'];\nconst PRIVATE = {\n  JOIN: Symbol('private:ConsumerGroup:join'),\n  SYNC: Symbol('private:ConsumerGroup:sync'),\n  SHARED_HEARTBEAT: Symbol('private:ConsumerGroup:sharedHeartbeat')\n};\nmodule.exports = class ConsumerGroup {\n  /**\n   * @param {object} options\n   * @param {import('../../types').RetryOptions} options.retry\n   * @param {import('../../types').Cluster} options.cluster\n   * @param {string} options.groupId\n   * @param {string[]} options.topics\n   * @param {Record<string, { fromBeginning?: boolean }>} options.topicConfigurations\n   * @param {import('../../types').Logger} options.logger\n   * @param {import('../instrumentation/emitter')} options.instrumentationEmitter\n   * @param {import('../../types').Assigner[]} options.assigners\n   * @param {number} options.sessionTimeout\n   * @param {number} options.rebalanceTimeout\n   * @param {number} options.maxBytesPerPartition\n   * @param {number} options.minBytes\n   * @param {number} options.maxBytes\n   * @param {number} options.maxWaitTimeInMs\n   * @param {boolean} options.autoCommit\n   * @param {number} options.autoCommitInterval\n   * @param {number} options.autoCommitThreshold\n   * @param {number} options.isolationLevel\n   * @param {string} options.rackId\n   * @param {number} options.metadataMaxAge\n   */\n  constructor({\n    retry,\n    cluster,\n    groupId,\n    topics,\n    topicConfigurations,\n    logger,\n    instrumentationEmitter,\n    assigners,\n    sessionTimeout,\n    rebalanceTimeout,\n    maxBytesPerPartition,\n    minBytes,\n    maxBytes,\n    maxWaitTimeInMs,\n    autoCommit,\n    autoCommitInterval,\n    autoCommitThreshold,\n    isolationLevel,\n    rackId,\n    metadataMaxAge\n  }) {\n    var _this = this;\n    /** @type {import(\"../../types\").Cluster} */\n    this.cluster = cluster;\n    this.groupId = groupId;\n    this.topics = topics;\n    this.topicsSubscribed = topics;\n    this.topicConfigurations = topicConfigurations;\n    this.logger = logger.namespace('ConsumerGroup');\n    this.instrumentationEmitter = instrumentationEmitter;\n    this.retrier = createRetry(Object.assign({}, retry));\n    this.assigners = assigners;\n    this.sessionTimeout = sessionTimeout;\n    this.rebalanceTimeout = rebalanceTimeout;\n    this.maxBytesPerPartition = maxBytesPerPartition;\n    this.minBytes = minBytes;\n    this.maxBytes = maxBytes;\n    this.maxWaitTime = maxWaitTimeInMs;\n    this.autoCommit = autoCommit;\n    this.autoCommitInterval = autoCommitInterval;\n    this.autoCommitThreshold = autoCommitThreshold;\n    this.isolationLevel = isolationLevel;\n    this.rackId = rackId;\n    this.metadataMaxAge = metadataMaxAge;\n    this.seekOffset = new SeekOffsets();\n    this.coordinator = null;\n    this.generationId = null;\n    this.leaderId = null;\n    this.memberId = null;\n    this.members = null;\n    this.groupProtocol = null;\n    this.partitionsPerSubscribedTopic = null;\n    /**\n     * Preferred read replica per topic and partition\n     *\n     * Each of the partitions tracks the preferred read replica (`nodeId`) and a timestamp\n     * until when that preference is valid.\n     *\n     * @type {{[topicName: string]: {[partition: number]: {nodeId: number, expireAt: number}}}}\n     */\n    this.preferredReadReplicasPerTopicPartition = {};\n    this.offsetManager = null;\n    this.subscriptionState = new SubscriptionState();\n    this.lastRequest = Date.now();\n    this[PRIVATE.SHARED_HEARTBEAT] = sharedPromiseTo( /*#__PURE__*/function () {\n      var _ref = _asyncToGenerator(function* ({\n        interval\n      }) {\n        const {\n          groupId,\n          generationId,\n          memberId\n        } = _this;\n        const now = Date.now();\n        if (memberId && now >= _this.lastRequest + interval) {\n          const payload = {\n            groupId,\n            memberId,\n            groupGenerationId: generationId\n          };\n          yield _this.coordinator.heartbeat(payload);\n          _this.instrumentationEmitter.emit(HEARTBEAT, payload);\n          _this.lastRequest = Date.now();\n        }\n      });\n      return function (_x) {\n        return _ref.apply(this, arguments);\n      };\n    }());\n  }\n  isLeader() {\n    return this.leaderId && this.memberId === this.leaderId;\n  }\n  getNodeIds() {\n    return this.cluster.getNodeIds();\n  }\n  connect() {\n    var _this2 = this;\n    return _asyncToGenerator(function* () {\n      yield _this2.cluster.connect();\n      _this2.instrumentationEmitter.emit(CONNECT);\n      yield _this2.cluster.refreshMetadataIfNecessary();\n    })();\n  }\n  [PRIVATE.JOIN]() {\n    var _this3 = this;\n    return _asyncToGenerator(function* () {\n      const {\n        groupId,\n        sessionTimeout,\n        rebalanceTimeout\n      } = _this3;\n      _this3.coordinator = yield _this3.cluster.findGroupCoordinator({\n        groupId\n      });\n      const groupData = yield _this3.coordinator.joinGroup({\n        groupId,\n        sessionTimeout,\n        rebalanceTimeout,\n        memberId: _this3.memberId || '',\n        groupProtocols: _this3.assigners.map(assigner => assigner.protocol({\n          topics: _this3.topicsSubscribed\n        }))\n      });\n      _this3.generationId = groupData.generationId;\n      _this3.leaderId = groupData.leaderId;\n      _this3.memberId = groupData.memberId;\n      _this3.members = groupData.members;\n      _this3.groupProtocol = groupData.groupProtocol;\n    })();\n  }\n  leave() {\n    var _this4 = this;\n    return _asyncToGenerator(function* () {\n      const {\n        groupId,\n        memberId\n      } = _this4;\n      if (memberId) {\n        yield _this4.coordinator.leaveGroup({\n          groupId,\n          memberId\n        });\n        _this4.memberId = null;\n      }\n    })();\n  }\n  [PRIVATE.SYNC]() {\n    var _this5 = this;\n    return _asyncToGenerator(function* () {\n      let assignment = [];\n      const {\n        groupId,\n        generationId,\n        memberId,\n        members,\n        groupProtocol,\n        topics,\n        topicsSubscribed,\n        coordinator\n      } = _this5;\n      if (_this5.isLeader()) {\n        _this5.logger.debug('Chosen as group leader', {\n          groupId,\n          generationId,\n          memberId,\n          topics\n        });\n        const assigner = _this5.assigners.find(({\n          name\n        }) => name === groupProtocol);\n        if (!assigner) {\n          throw new KafkaJSNonRetriableError(`Unsupported partition assigner \"${groupProtocol}\", the assigner wasn't found in the assigners list`);\n        }\n        yield _this5.cluster.refreshMetadata();\n        assignment = yield assigner.assign({\n          members,\n          topics: topicsSubscribed\n        });\n        _this5.logger.debug('Group assignment', {\n          groupId,\n          generationId,\n          groupProtocol,\n          assignment,\n          topics: topicsSubscribed\n        });\n      }\n\n      // Keep track of the partitions for the subscribed topics\n      _this5.partitionsPerSubscribedTopic = _this5.generatePartitionsPerSubscribedTopic();\n      const {\n        memberAssignment\n      } = yield _this5.coordinator.syncGroup({\n        groupId,\n        generationId,\n        memberId,\n        groupAssignment: assignment\n      });\n      const decodedMemberAssignment = MemberAssignment.decode(memberAssignment);\n      const decodedAssignment = decodedMemberAssignment != null ? decodedMemberAssignment.assignment : {};\n      _this5.logger.debug('Received assignment', {\n        groupId,\n        generationId,\n        memberId,\n        memberAssignment: decodedAssignment\n      });\n      const assignedTopics = keys(decodedAssignment);\n      const topicsNotSubscribed = arrayDiff(assignedTopics, topicsSubscribed);\n      if (topicsNotSubscribed.length > 0) {\n        const payload = {\n          groupId,\n          generationId,\n          memberId,\n          assignedTopics,\n          topicsSubscribed,\n          topicsNotSubscribed\n        };\n        _this5.instrumentationEmitter.emit(RECEIVED_UNSUBSCRIBED_TOPICS, payload);\n        _this5.logger.warn('Consumer group received unsubscribed topics', {\n          ...payload,\n          helpUrl: websiteUrl('docs/faq', 'why-am-i-receiving-messages-for-topics-i-m-not-subscribed-to')\n        });\n      }\n\n      // Remove unsubscribed topics from the list\n      const safeAssignment = arrayDiff(assignedTopics, topicsNotSubscribed);\n      const currentMemberAssignment = safeAssignment.map(topic => ({\n        topic,\n        partitions: decodedAssignment[topic]\n      }));\n\n      // Check if the consumer is aware of all assigned partitions\n      for (const assignment of currentMemberAssignment) {\n        const {\n          topic,\n          partitions: assignedPartitions\n        } = assignment;\n        const knownPartitions = _this5.partitionsPerSubscribedTopic.get(topic);\n        const isAwareOfAllAssignedPartitions = assignedPartitions.every(partition => knownPartitions.includes(partition));\n        if (!isAwareOfAllAssignedPartitions) {\n          _this5.logger.warn('Consumer is not aware of all assigned partitions, refreshing metadata', {\n            groupId,\n            generationId,\n            memberId,\n            topic,\n            knownPartitions,\n            assignedPartitions\n          });\n\n          // If the consumer is not aware of all assigned partitions, refresh metadata\n          // and update the list of partitions per subscribed topic. It's enough to perform\n          // this operation once since refresh metadata will update metadata for all topics\n          yield _this5.cluster.refreshMetadata();\n          _this5.partitionsPerSubscribedTopic = _this5.generatePartitionsPerSubscribedTopic();\n          break;\n        }\n      }\n      _this5.topics = currentMemberAssignment.map(({\n        topic\n      }) => topic);\n      _this5.subscriptionState.assign(currentMemberAssignment);\n      _this5.offsetManager = new OffsetManager({\n        cluster: _this5.cluster,\n        topicConfigurations: _this5.topicConfigurations,\n        instrumentationEmitter: _this5.instrumentationEmitter,\n        memberAssignment: currentMemberAssignment.reduce((partitionsByTopic, {\n          topic,\n          partitions\n        }) => ({\n          ...partitionsByTopic,\n          [topic]: partitions\n        }), {}),\n        autoCommit: _this5.autoCommit,\n        autoCommitInterval: _this5.autoCommitInterval,\n        autoCommitThreshold: _this5.autoCommitThreshold,\n        coordinator,\n        groupId,\n        generationId,\n        memberId\n      });\n    })();\n  }\n  joinAndSync() {\n    var _this6 = this;\n    const startJoin = Date.now();\n    return this.retrier( /*#__PURE__*/function () {\n      var _ref2 = _asyncToGenerator(function* (bail) {\n        try {\n          yield _this6[PRIVATE.JOIN]();\n          yield _this6[PRIVATE.SYNC]();\n          const memberAssignment = _this6.assigned().reduce((result, {\n            topic,\n            partitions\n          }) => ({\n            ...result,\n            [topic]: partitions\n          }), {});\n          const payload = {\n            groupId: _this6.groupId,\n            memberId: _this6.memberId,\n            leaderId: _this6.leaderId,\n            isLeader: _this6.isLeader(),\n            memberAssignment,\n            groupProtocol: _this6.groupProtocol,\n            duration: Date.now() - startJoin\n          };\n          _this6.instrumentationEmitter.emit(GROUP_JOIN, payload);\n          _this6.logger.info('Consumer has joined the group', payload);\n        } catch (e) {\n          if (isRebalancing(e)) {\n            // Rebalance in progress isn't a retriable protocol error since the consumer\n            // has to go through find coordinator and join again before it can\n            // actually retry the operation. We wrap the original error in a retriable error\n            // here instead in order to restart the join + sync sequence using the retrier.\n            throw new KafkaJSError(e);\n          }\n          if (e.type === 'UNKNOWN_MEMBER_ID') {\n            _this6.memberId = null;\n            throw new KafkaJSError(e);\n          }\n          bail(e);\n        }\n      });\n      return function (_x2) {\n        return _ref2.apply(this, arguments);\n      };\n    }());\n  }\n\n  /**\n   * @param {import(\"../../types\").TopicPartition} topicPartition\n   */\n  resetOffset({\n    topic,\n    partition\n  }) {\n    this.offsetManager.resetOffset({\n      topic,\n      partition\n    });\n  }\n\n  /**\n   * @param {import(\"../../types\").TopicPartitionOffset} topicPartitionOffset\n   */\n  resolveOffset({\n    topic,\n    partition,\n    offset\n  }) {\n    this.offsetManager.resolveOffset({\n      topic,\n      partition,\n      offset\n    });\n  }\n\n  /**\n   * Update the consumer offset for the given topic/partition. This will be used\n   * on the next fetch. If this API is invoked for the same topic/partition more\n   * than once, the latest offset will be used on the next fetch.\n   *\n   * @param {import(\"../../types\").TopicPartitionOffset} topicPartitionOffset\n   */\n  seek({\n    topic,\n    partition,\n    offset\n  }) {\n    this.seekOffset.set(topic, partition, offset);\n  }\n  pause(topicPartitions) {\n    this.logger.info(`Pausing fetching from ${topicPartitions.length} topics`, {\n      topicPartitions\n    });\n    this.subscriptionState.pause(topicPartitions);\n  }\n  resume(topicPartitions) {\n    this.logger.info(`Resuming fetching from ${topicPartitions.length} topics`, {\n      topicPartitions\n    });\n    this.subscriptionState.resume(topicPartitions);\n  }\n  assigned() {\n    return this.subscriptionState.assigned();\n  }\n  paused() {\n    return this.subscriptionState.paused();\n  }\n\n  /**\n   * @param {string} topic\n   * @param {string} partition\n   * @returns {boolean} whether the specified topic-partition are paused or not\n   */\n  isPaused(topic, partition) {\n    return this.subscriptionState.isPaused(topic, partition);\n  }\n  commitOffsetsIfNecessary() {\n    var _this7 = this;\n    return _asyncToGenerator(function* () {\n      yield _this7.offsetManager.commitOffsetsIfNecessary();\n    })();\n  }\n  commitOffsets(offsets) {\n    var _this8 = this;\n    return _asyncToGenerator(function* () {\n      yield _this8.offsetManager.commitOffsets(offsets);\n    })();\n  }\n  uncommittedOffsets() {\n    return this.offsetManager.uncommittedOffsets();\n  }\n  heartbeat({\n    interval\n  }) {\n    var _this9 = this;\n    return _asyncToGenerator(function* () {\n      return _this9[PRIVATE.SHARED_HEARTBEAT]({\n        interval\n      });\n    })();\n  }\n  fetch(nodeId) {\n    var _this10 = this;\n    return _asyncToGenerator(function* () {\n      try {\n        yield _this10.cluster.refreshMetadataIfNecessary();\n        _this10.checkForStaleAssignment();\n        let topicPartitions = _this10.subscriptionState.assigned();\n        topicPartitions = _this10.filterPartitionsByNode(nodeId, topicPartitions);\n        yield _this10.seekOffsets(topicPartitions);\n        const committedOffsets = _this10.offsetManager.committedOffsets();\n        const activeTopicPartitions = _this10.getActiveTopicPartitions();\n        const requests = topicPartitions.map(({\n          topic,\n          partitions\n        }) => ({\n          topic,\n          partitions: partitions.filter(partition =>\n          /**\n           * When recovering from OffsetOutOfRange, each partition can recover\n           * concurrently, which invalidates resolved and committed offsets as part\n           * of the recovery mechanism (see OffsetManager.clearOffsets). In concurrent\n           * scenarios this can initiate a new fetch with invalid offsets.\n           *\n           * This was further highlighted by https://github.com/tulios/kafkajs/pull/570,\n           * which increased concurrency, making this more likely to happen.\n           *\n           * This is solved by only making requests for partitions with initialized offsets.\n           *\n           * See the following pull request which explains the context of the problem:\n           * @issue https://github.com/tulios/kafkajs/pull/578\n           */\n          committedOffsets[topic][partition] != null && activeTopicPartitions[topic].has(partition)).map(partition => ({\n            partition,\n            fetchOffset: _this10.offsetManager.nextOffset(topic, partition).toString(),\n            maxBytes: _this10.maxBytesPerPartition\n          }))\n        })).filter(({\n          partitions\n        }) => partitions.length);\n        if (!requests.length) {\n          yield sleep(_this10.maxWaitTime);\n          return [];\n        }\n        const broker = yield _this10.cluster.findBroker({\n          nodeId\n        });\n        const {\n          responses\n        } = yield broker.fetch({\n          maxWaitTime: _this10.maxWaitTime,\n          minBytes: _this10.minBytes,\n          maxBytes: _this10.maxBytes,\n          isolationLevel: _this10.isolationLevel,\n          topics: requests,\n          rackId: _this10.rackId\n        });\n        return responses.flatMap(({\n          topicName,\n          partitions\n        }) => {\n          const topicRequestData = requests.find(({\n            topic\n          }) => topic === topicName);\n          let preferredReadReplicas = _this10.preferredReadReplicasPerTopicPartition[topicName];\n          if (!preferredReadReplicas) {\n            _this10.preferredReadReplicasPerTopicPartition[topicName] = preferredReadReplicas = {};\n          }\n          return partitions.filter(({\n            partition\n          }) => !_this10.seekOffset.has(topicName, partition) && !_this10.subscriptionState.isPaused(topicName, partition)).map(partitionData => {\n            const {\n              partition,\n              preferredReadReplica\n            } = partitionData;\n            if (preferredReadReplica != null && preferredReadReplica !== -1) {\n              const {\n                nodeId: currentPreferredReadReplica\n              } = preferredReadReplicas[partition] || {};\n              if (currentPreferredReadReplica !== preferredReadReplica) {\n                _this10.logger.info(`Preferred read replica is now ${preferredReadReplica}`, {\n                  groupId: _this10.groupId,\n                  memberId: _this10.memberId,\n                  topic: topicName,\n                  partition\n                });\n              }\n              preferredReadReplicas[partition] = {\n                nodeId: preferredReadReplica,\n                expireAt: Date.now() + _this10.metadataMaxAge\n              };\n            }\n            const partitionRequestData = topicRequestData.partitions.find(({\n              partition\n            }) => partition === partitionData.partition);\n            const fetchedOffset = partitionRequestData.fetchOffset;\n            return new Batch(topicName, fetchedOffset, partitionData);\n          });\n        });\n      } catch (e) {\n        yield _this10.recoverFromFetch(e);\n        return [];\n      }\n    })();\n  }\n  recoverFromFetch(e) {\n    var _this11 = this;\n    return _asyncToGenerator(function* () {\n      if (STALE_METADATA_ERRORS.includes(e.type) || e.name === 'KafkaJSTopicMetadataNotLoaded') {\n        _this11.logger.debug('Stale cluster metadata, refreshing...', {\n          groupId: _this11.groupId,\n          memberId: _this11.memberId,\n          error: e.message\n        });\n        yield _this11.cluster.refreshMetadata();\n        yield _this11.joinAndSync();\n        return;\n      }\n      if (e.name === 'KafkaJSStaleTopicMetadataAssignment') {\n        _this11.logger.warn(`${e.message}, resync group`, {\n          groupId: _this11.groupId,\n          memberId: _this11.memberId,\n          topic: e.topic,\n          unknownPartitions: e.unknownPartitions\n        });\n        yield _this11.joinAndSync();\n        return;\n      }\n      if (e.name === 'KafkaJSOffsetOutOfRange') {\n        yield _this11.recoverFromOffsetOutOfRange(e);\n        return;\n      }\n      if (e.name === 'KafkaJSConnectionClosedError') {\n        _this11.cluster.removeBroker({\n          host: e.host,\n          port: e.port\n        });\n        return;\n      }\n      if (e.name === 'KafkaJSBrokerNotFound' || e.name === 'KafkaJSConnectionClosedError') {\n        _this11.logger.debug(`${e.message}, refreshing metadata and retrying...`);\n        yield _this11.cluster.refreshMetadata();\n        return;\n      }\n      throw e;\n    })();\n  }\n  recoverFromOffsetOutOfRange(e) {\n    var _this12 = this;\n    return _asyncToGenerator(function* () {\n      // If we are fetching from a follower try with the leader before resetting offsets\n      const preferredReadReplicas = _this12.preferredReadReplicasPerTopicPartition[e.topic];\n      if (preferredReadReplicas && typeof preferredReadReplicas[e.partition] === 'number') {\n        _this12.logger.info('Offset out of range while fetching from follower, retrying with leader', {\n          topic: e.topic,\n          partition: e.partition,\n          groupId: _this12.groupId,\n          memberId: _this12.memberId\n        });\n        delete preferredReadReplicas[e.partition];\n      } else {\n        _this12.logger.error('Offset out of range, resetting to default offset', {\n          topic: e.topic,\n          partition: e.partition,\n          groupId: _this12.groupId,\n          memberId: _this12.memberId\n        });\n        yield _this12.offsetManager.setDefaultOffset({\n          topic: e.topic,\n          partition: e.partition\n        });\n      }\n    })();\n  }\n  generatePartitionsPerSubscribedTopic() {\n    const map = new Map();\n    for (const topic of this.topicsSubscribed) {\n      const partitions = this.cluster.findTopicPartitionMetadata(topic).map(m => m.partitionId).sort();\n      map.set(topic, partitions);\n    }\n    return map;\n  }\n  checkForStaleAssignment() {\n    if (!this.partitionsPerSubscribedTopic) {\n      return;\n    }\n    const newPartitionsPerSubscribedTopic = this.generatePartitionsPerSubscribedTopic();\n    for (const [topic, partitions] of newPartitionsPerSubscribedTopic) {\n      const diff = arrayDiff(partitions, this.partitionsPerSubscribedTopic.get(topic));\n      if (diff.length > 0) {\n        throw new KafkaJSStaleTopicMetadataAssignment('Topic has been updated', {\n          topic,\n          unknownPartitions: diff\n        });\n      }\n    }\n  }\n  seekOffsets(topicPartitions) {\n    var _this13 = this;\n    return _asyncToGenerator(function* () {\n      for (const {\n        topic,\n        partitions\n      } of topicPartitions) {\n        for (const partition of partitions) {\n          const seekEntry = _this13.seekOffset.pop(topic, partition);\n          if (!seekEntry) {\n            continue;\n          }\n          _this13.logger.debug('Seek offset', {\n            groupId: _this13.groupId,\n            memberId: _this13.memberId,\n            seek: seekEntry\n          });\n          yield _this13.offsetManager.seek(seekEntry);\n        }\n      }\n      yield _this13.offsetManager.resolveOffsets();\n    })();\n  }\n  hasSeekOffset({\n    topic,\n    partition\n  }) {\n    return this.seekOffset.has(topic, partition);\n  }\n\n  /**\n   * For each of the partitions find the best nodeId to read it from\n   *\n   * @param {string} topic\n   * @param {number[]} partitions\n   * @returns {{[nodeId: number]: number[]}} per-node assignment of partitions\n   * @see Cluster~findLeaderForPartitions\n   */\n  // Invariant: The resulting object has each partition referenced exactly once\n  findReadReplicaForPartitions(topic, partitions) {\n    const partitionMetadata = this.cluster.findTopicPartitionMetadata(topic);\n    const preferredReadReplicas = this.preferredReadReplicasPerTopicPartition[topic];\n    return partitions.reduce((result, id) => {\n      const partitionId = parseInt(id, 10);\n      const metadata = partitionMetadata.find(p => p.partitionId === partitionId);\n      if (!metadata) {\n        return result;\n      }\n      if (metadata.leader == null) {\n        throw new KafkaJSError('Invalid partition metadata', {\n          topic,\n          partitionId,\n          metadata\n        });\n      }\n\n      // Pick the preferred replica if there is one, and it isn't known to be offline, otherwise the leader.\n      let nodeId = metadata.leader;\n      if (preferredReadReplicas) {\n        const {\n          nodeId: preferredReadReplica,\n          expireAt\n        } = preferredReadReplicas[partitionId] || {};\n        if (Date.now() >= expireAt) {\n          this.logger.debug('Preferred read replica information has expired, using leader', {\n            topic,\n            partitionId,\n            groupId: this.groupId,\n            memberId: this.memberId,\n            preferredReadReplica,\n            leader: metadata.leader\n          });\n          // Drop the entry\n          delete preferredReadReplicas[partitionId];\n        } else if (preferredReadReplica != null) {\n          // Valid entry, check whether it is not offline\n          // Note that we don't delete the preference here, and rather hope that eventually that replica comes online again\n          const offlineReplicas = metadata.offlineReplicas;\n          if (Array.isArray(offlineReplicas) && offlineReplicas.includes(nodeId)) {\n            this.logger.debug('Preferred read replica is offline, using leader', {\n              topic,\n              partitionId,\n              groupId: this.groupId,\n              memberId: this.memberId,\n              preferredReadReplica,\n              leader: metadata.leader\n            });\n          } else {\n            nodeId = preferredReadReplica;\n          }\n        }\n      }\n      const current = result[nodeId] || [];\n      return {\n        ...result,\n        [nodeId]: [...current, partitionId]\n      };\n    }, {});\n  }\n  filterPartitionsByNode(nodeId, topicPartitions) {\n    return topicPartitions.map(({\n      topic,\n      partitions\n    }) => ({\n      topic,\n      partitions: this.findReadReplicaForPartitions(topic, partitions)[nodeId] || []\n    }));\n  }\n  getActiveTopicPartitions() {\n    const activeSubscriptionState = this.subscriptionState.active();\n    const activeTopicPartitions = {};\n    activeSubscriptionState.forEach(({\n      topic,\n      partitions\n    }) => {\n      activeTopicPartitions[topic] = new Set(partitions);\n    });\n    return activeTopicPartitions;\n  }\n};","map":{"version":3,"names":["sleep","require","websiteUrl","arrayDiff","createRetry","sharedPromiseTo","OffsetManager","Batch","SeekOffsets","SubscriptionState","events","GROUP_JOIN","HEARTBEAT","CONNECT","RECEIVED_UNSUBSCRIBED_TOPICS","MemberAssignment","KafkaJSError","KafkaJSNonRetriableError","KafkaJSStaleTopicMetadataAssignment","isRebalancing","keys","Object","STALE_METADATA_ERRORS","PRIVATE","JOIN","Symbol","SYNC","SHARED_HEARTBEAT","module","exports","ConsumerGroup","constructor","retry","cluster","groupId","topics","topicConfigurations","logger","instrumentationEmitter","assigners","sessionTimeout","rebalanceTimeout","maxBytesPerPartition","minBytes","maxBytes","maxWaitTimeInMs","autoCommit","autoCommitInterval","autoCommitThreshold","isolationLevel","rackId","metadataMaxAge","topicsSubscribed","namespace","retrier","assign","maxWaitTime","seekOffset","coordinator","generationId","leaderId","memberId","members","groupProtocol","partitionsPerSubscribedTopic","preferredReadReplicasPerTopicPartition","offsetManager","subscriptionState","lastRequest","Date","now","interval","payload","groupGenerationId","heartbeat","emit","isLeader","getNodeIds","connect","refreshMetadataIfNecessary","findGroupCoordinator","groupData","joinGroup","groupProtocols","map","assigner","protocol","leave","leaveGroup","assignment","debug","find","name","refreshMetadata","generatePartitionsPerSubscribedTopic","memberAssignment","syncGroup","groupAssignment","decodedMemberAssignment","decode","decodedAssignment","assignedTopics","topicsNotSubscribed","length","warn","helpUrl","safeAssignment","currentMemberAssignment","topic","partitions","assignedPartitions","knownPartitions","get","isAwareOfAllAssignedPartitions","every","partition","includes","reduce","partitionsByTopic","joinAndSync","startJoin","bail","assigned","result","duration","info","e","type","resetOffset","resolveOffset","offset","seek","set","pause","topicPartitions","resume","paused","isPaused","commitOffsetsIfNecessary","commitOffsets","offsets","uncommittedOffsets","fetch","nodeId","checkForStaleAssignment","filterPartitionsByNode","seekOffsets","committedOffsets","activeTopicPartitions","getActiveTopicPartitions","requests","filter","has","fetchOffset","nextOffset","toString","broker","findBroker","responses","flatMap","topicName","topicRequestData","preferredReadReplicas","partitionData","preferredReadReplica","currentPreferredReadReplica","expireAt","partitionRequestData","fetchedOffset","recoverFromFetch","error","message","unknownPartitions","recoverFromOffsetOutOfRange","removeBroker","host","port","setDefaultOffset","Map","findTopicPartitionMetadata","m","partitionId","sort","newPartitionsPerSubscribedTopic","diff","seekEntry","pop","resolveOffsets","hasSeekOffset","findReadReplicaForPartitions","partitionMetadata","id","parseInt","metadata","p","leader","offlineReplicas","Array","isArray","current","activeSubscriptionState","active","forEach","Set"],"sources":["C:/Users/ingev/Documents/Desarrollo/Luna/DronController/AD_UI/node_modules/kafkajs/src/consumer/consumerGroup.js"],"sourcesContent":["const sleep = require('../utils/sleep')\nconst websiteUrl = require('../utils/websiteUrl')\nconst arrayDiff = require('../utils/arrayDiff')\nconst createRetry = require('../retry')\nconst sharedPromiseTo = require('../utils/sharedPromiseTo')\n\nconst OffsetManager = require('./offsetManager')\nconst Batch = require('./batch')\nconst SeekOffsets = require('./seekOffsets')\nconst SubscriptionState = require('./subscriptionState')\nconst {\n  events: { GROUP_JOIN, HEARTBEAT, CONNECT, RECEIVED_UNSUBSCRIBED_TOPICS },\n} = require('./instrumentationEvents')\nconst { MemberAssignment } = require('./assignerProtocol')\nconst {\n  KafkaJSError,\n  KafkaJSNonRetriableError,\n  KafkaJSStaleTopicMetadataAssignment,\n  isRebalancing,\n} = require('../errors')\n\nconst { keys } = Object\n\nconst STALE_METADATA_ERRORS = [\n  'LEADER_NOT_AVAILABLE',\n  // Fetch before v9 uses NOT_LEADER_FOR_PARTITION\n  'NOT_LEADER_FOR_PARTITION',\n  // Fetch after v9 uses {FENCED,UNKNOWN}_LEADER_EPOCH\n  'FENCED_LEADER_EPOCH',\n  'UNKNOWN_LEADER_EPOCH',\n  'UNKNOWN_TOPIC_OR_PARTITION',\n]\n\nconst PRIVATE = {\n  JOIN: Symbol('private:ConsumerGroup:join'),\n  SYNC: Symbol('private:ConsumerGroup:sync'),\n  SHARED_HEARTBEAT: Symbol('private:ConsumerGroup:sharedHeartbeat'),\n}\n\nmodule.exports = class ConsumerGroup {\n  /**\n   * @param {object} options\n   * @param {import('../../types').RetryOptions} options.retry\n   * @param {import('../../types').Cluster} options.cluster\n   * @param {string} options.groupId\n   * @param {string[]} options.topics\n   * @param {Record<string, { fromBeginning?: boolean }>} options.topicConfigurations\n   * @param {import('../../types').Logger} options.logger\n   * @param {import('../instrumentation/emitter')} options.instrumentationEmitter\n   * @param {import('../../types').Assigner[]} options.assigners\n   * @param {number} options.sessionTimeout\n   * @param {number} options.rebalanceTimeout\n   * @param {number} options.maxBytesPerPartition\n   * @param {number} options.minBytes\n   * @param {number} options.maxBytes\n   * @param {number} options.maxWaitTimeInMs\n   * @param {boolean} options.autoCommit\n   * @param {number} options.autoCommitInterval\n   * @param {number} options.autoCommitThreshold\n   * @param {number} options.isolationLevel\n   * @param {string} options.rackId\n   * @param {number} options.metadataMaxAge\n   */\n  constructor({\n    retry,\n    cluster,\n    groupId,\n    topics,\n    topicConfigurations,\n    logger,\n    instrumentationEmitter,\n    assigners,\n    sessionTimeout,\n    rebalanceTimeout,\n    maxBytesPerPartition,\n    minBytes,\n    maxBytes,\n    maxWaitTimeInMs,\n    autoCommit,\n    autoCommitInterval,\n    autoCommitThreshold,\n    isolationLevel,\n    rackId,\n    metadataMaxAge,\n  }) {\n    /** @type {import(\"../../types\").Cluster} */\n    this.cluster = cluster\n    this.groupId = groupId\n    this.topics = topics\n    this.topicsSubscribed = topics\n    this.topicConfigurations = topicConfigurations\n    this.logger = logger.namespace('ConsumerGroup')\n    this.instrumentationEmitter = instrumentationEmitter\n    this.retrier = createRetry(Object.assign({}, retry))\n    this.assigners = assigners\n    this.sessionTimeout = sessionTimeout\n    this.rebalanceTimeout = rebalanceTimeout\n    this.maxBytesPerPartition = maxBytesPerPartition\n    this.minBytes = minBytes\n    this.maxBytes = maxBytes\n    this.maxWaitTime = maxWaitTimeInMs\n    this.autoCommit = autoCommit\n    this.autoCommitInterval = autoCommitInterval\n    this.autoCommitThreshold = autoCommitThreshold\n    this.isolationLevel = isolationLevel\n    this.rackId = rackId\n    this.metadataMaxAge = metadataMaxAge\n\n    this.seekOffset = new SeekOffsets()\n    this.coordinator = null\n    this.generationId = null\n    this.leaderId = null\n    this.memberId = null\n    this.members = null\n    this.groupProtocol = null\n\n    this.partitionsPerSubscribedTopic = null\n    /**\n     * Preferred read replica per topic and partition\n     *\n     * Each of the partitions tracks the preferred read replica (`nodeId`) and a timestamp\n     * until when that preference is valid.\n     *\n     * @type {{[topicName: string]: {[partition: number]: {nodeId: number, expireAt: number}}}}\n     */\n    this.preferredReadReplicasPerTopicPartition = {}\n    this.offsetManager = null\n    this.subscriptionState = new SubscriptionState()\n\n    this.lastRequest = Date.now()\n\n    this[PRIVATE.SHARED_HEARTBEAT] = sharedPromiseTo(async ({ interval }) => {\n      const { groupId, generationId, memberId } = this\n      const now = Date.now()\n\n      if (memberId && now >= this.lastRequest + interval) {\n        const payload = {\n          groupId,\n          memberId,\n          groupGenerationId: generationId,\n        }\n\n        await this.coordinator.heartbeat(payload)\n        this.instrumentationEmitter.emit(HEARTBEAT, payload)\n        this.lastRequest = Date.now()\n      }\n    })\n  }\n\n  isLeader() {\n    return this.leaderId && this.memberId === this.leaderId\n  }\n\n  getNodeIds() {\n    return this.cluster.getNodeIds()\n  }\n\n  async connect() {\n    await this.cluster.connect()\n    this.instrumentationEmitter.emit(CONNECT)\n    await this.cluster.refreshMetadataIfNecessary()\n  }\n\n  async [PRIVATE.JOIN]() {\n    const { groupId, sessionTimeout, rebalanceTimeout } = this\n\n    this.coordinator = await this.cluster.findGroupCoordinator({ groupId })\n\n    const groupData = await this.coordinator.joinGroup({\n      groupId,\n      sessionTimeout,\n      rebalanceTimeout,\n      memberId: this.memberId || '',\n      groupProtocols: this.assigners.map(assigner =>\n        assigner.protocol({\n          topics: this.topicsSubscribed,\n        })\n      ),\n    })\n\n    this.generationId = groupData.generationId\n    this.leaderId = groupData.leaderId\n    this.memberId = groupData.memberId\n    this.members = groupData.members\n    this.groupProtocol = groupData.groupProtocol\n  }\n\n  async leave() {\n    const { groupId, memberId } = this\n    if (memberId) {\n      await this.coordinator.leaveGroup({ groupId, memberId })\n      this.memberId = null\n    }\n  }\n\n  async [PRIVATE.SYNC]() {\n    let assignment = []\n    const {\n      groupId,\n      generationId,\n      memberId,\n      members,\n      groupProtocol,\n      topics,\n      topicsSubscribed,\n      coordinator,\n    } = this\n\n    if (this.isLeader()) {\n      this.logger.debug('Chosen as group leader', { groupId, generationId, memberId, topics })\n      const assigner = this.assigners.find(({ name }) => name === groupProtocol)\n\n      if (!assigner) {\n        throw new KafkaJSNonRetriableError(\n          `Unsupported partition assigner \"${groupProtocol}\", the assigner wasn't found in the assigners list`\n        )\n      }\n\n      await this.cluster.refreshMetadata()\n      assignment = await assigner.assign({ members, topics: topicsSubscribed })\n\n      this.logger.debug('Group assignment', {\n        groupId,\n        generationId,\n        groupProtocol,\n        assignment,\n        topics: topicsSubscribed,\n      })\n    }\n\n    // Keep track of the partitions for the subscribed topics\n    this.partitionsPerSubscribedTopic = this.generatePartitionsPerSubscribedTopic()\n    const { memberAssignment } = await this.coordinator.syncGroup({\n      groupId,\n      generationId,\n      memberId,\n      groupAssignment: assignment,\n    })\n\n    const decodedMemberAssignment = MemberAssignment.decode(memberAssignment)\n    const decodedAssignment =\n      decodedMemberAssignment != null ? decodedMemberAssignment.assignment : {}\n\n    this.logger.debug('Received assignment', {\n      groupId,\n      generationId,\n      memberId,\n      memberAssignment: decodedAssignment,\n    })\n\n    const assignedTopics = keys(decodedAssignment)\n    const topicsNotSubscribed = arrayDiff(assignedTopics, topicsSubscribed)\n\n    if (topicsNotSubscribed.length > 0) {\n      const payload = {\n        groupId,\n        generationId,\n        memberId,\n        assignedTopics,\n        topicsSubscribed,\n        topicsNotSubscribed,\n      }\n\n      this.instrumentationEmitter.emit(RECEIVED_UNSUBSCRIBED_TOPICS, payload)\n      this.logger.warn('Consumer group received unsubscribed topics', {\n        ...payload,\n        helpUrl: websiteUrl(\n          'docs/faq',\n          'why-am-i-receiving-messages-for-topics-i-m-not-subscribed-to'\n        ),\n      })\n    }\n\n    // Remove unsubscribed topics from the list\n    const safeAssignment = arrayDiff(assignedTopics, topicsNotSubscribed)\n    const currentMemberAssignment = safeAssignment.map(topic => ({\n      topic,\n      partitions: decodedAssignment[topic],\n    }))\n\n    // Check if the consumer is aware of all assigned partitions\n    for (const assignment of currentMemberAssignment) {\n      const { topic, partitions: assignedPartitions } = assignment\n      const knownPartitions = this.partitionsPerSubscribedTopic.get(topic)\n      const isAwareOfAllAssignedPartitions = assignedPartitions.every(partition =>\n        knownPartitions.includes(partition)\n      )\n\n      if (!isAwareOfAllAssignedPartitions) {\n        this.logger.warn('Consumer is not aware of all assigned partitions, refreshing metadata', {\n          groupId,\n          generationId,\n          memberId,\n          topic,\n          knownPartitions,\n          assignedPartitions,\n        })\n\n        // If the consumer is not aware of all assigned partitions, refresh metadata\n        // and update the list of partitions per subscribed topic. It's enough to perform\n        // this operation once since refresh metadata will update metadata for all topics\n        await this.cluster.refreshMetadata()\n        this.partitionsPerSubscribedTopic = this.generatePartitionsPerSubscribedTopic()\n        break\n      }\n    }\n\n    this.topics = currentMemberAssignment.map(({ topic }) => topic)\n    this.subscriptionState.assign(currentMemberAssignment)\n    this.offsetManager = new OffsetManager({\n      cluster: this.cluster,\n      topicConfigurations: this.topicConfigurations,\n      instrumentationEmitter: this.instrumentationEmitter,\n      memberAssignment: currentMemberAssignment.reduce(\n        (partitionsByTopic, { topic, partitions }) => ({\n          ...partitionsByTopic,\n          [topic]: partitions,\n        }),\n        {}\n      ),\n      autoCommit: this.autoCommit,\n      autoCommitInterval: this.autoCommitInterval,\n      autoCommitThreshold: this.autoCommitThreshold,\n      coordinator,\n      groupId,\n      generationId,\n      memberId,\n    })\n  }\n\n  joinAndSync() {\n    const startJoin = Date.now()\n    return this.retrier(async bail => {\n      try {\n        await this[PRIVATE.JOIN]()\n        await this[PRIVATE.SYNC]()\n\n        const memberAssignment = this.assigned().reduce(\n          (result, { topic, partitions }) => ({ ...result, [topic]: partitions }),\n          {}\n        )\n\n        const payload = {\n          groupId: this.groupId,\n          memberId: this.memberId,\n          leaderId: this.leaderId,\n          isLeader: this.isLeader(),\n          memberAssignment,\n          groupProtocol: this.groupProtocol,\n          duration: Date.now() - startJoin,\n        }\n\n        this.instrumentationEmitter.emit(GROUP_JOIN, payload)\n        this.logger.info('Consumer has joined the group', payload)\n      } catch (e) {\n        if (isRebalancing(e)) {\n          // Rebalance in progress isn't a retriable protocol error since the consumer\n          // has to go through find coordinator and join again before it can\n          // actually retry the operation. We wrap the original error in a retriable error\n          // here instead in order to restart the join + sync sequence using the retrier.\n          throw new KafkaJSError(e)\n        }\n\n        if (e.type === 'UNKNOWN_MEMBER_ID') {\n          this.memberId = null\n          throw new KafkaJSError(e)\n        }\n\n        bail(e)\n      }\n    })\n  }\n\n  /**\n   * @param {import(\"../../types\").TopicPartition} topicPartition\n   */\n  resetOffset({ topic, partition }) {\n    this.offsetManager.resetOffset({ topic, partition })\n  }\n\n  /**\n   * @param {import(\"../../types\").TopicPartitionOffset} topicPartitionOffset\n   */\n  resolveOffset({ topic, partition, offset }) {\n    this.offsetManager.resolveOffset({ topic, partition, offset })\n  }\n\n  /**\n   * Update the consumer offset for the given topic/partition. This will be used\n   * on the next fetch. If this API is invoked for the same topic/partition more\n   * than once, the latest offset will be used on the next fetch.\n   *\n   * @param {import(\"../../types\").TopicPartitionOffset} topicPartitionOffset\n   */\n  seek({ topic, partition, offset }) {\n    this.seekOffset.set(topic, partition, offset)\n  }\n\n  pause(topicPartitions) {\n    this.logger.info(`Pausing fetching from ${topicPartitions.length} topics`, {\n      topicPartitions,\n    })\n    this.subscriptionState.pause(topicPartitions)\n  }\n\n  resume(topicPartitions) {\n    this.logger.info(`Resuming fetching from ${topicPartitions.length} topics`, {\n      topicPartitions,\n    })\n    this.subscriptionState.resume(topicPartitions)\n  }\n\n  assigned() {\n    return this.subscriptionState.assigned()\n  }\n\n  paused() {\n    return this.subscriptionState.paused()\n  }\n\n  /**\n   * @param {string} topic\n   * @param {string} partition\n   * @returns {boolean} whether the specified topic-partition are paused or not\n   */\n  isPaused(topic, partition) {\n    return this.subscriptionState.isPaused(topic, partition)\n  }\n\n  async commitOffsetsIfNecessary() {\n    await this.offsetManager.commitOffsetsIfNecessary()\n  }\n\n  async commitOffsets(offsets) {\n    await this.offsetManager.commitOffsets(offsets)\n  }\n\n  uncommittedOffsets() {\n    return this.offsetManager.uncommittedOffsets()\n  }\n\n  async heartbeat({ interval }) {\n    return this[PRIVATE.SHARED_HEARTBEAT]({ interval })\n  }\n\n  async fetch(nodeId) {\n    try {\n      await this.cluster.refreshMetadataIfNecessary()\n      this.checkForStaleAssignment()\n\n      let topicPartitions = this.subscriptionState.assigned()\n      topicPartitions = this.filterPartitionsByNode(nodeId, topicPartitions)\n\n      await this.seekOffsets(topicPartitions)\n\n      const committedOffsets = this.offsetManager.committedOffsets()\n      const activeTopicPartitions = this.getActiveTopicPartitions()\n\n      const requests = topicPartitions\n        .map(({ topic, partitions }) => ({\n          topic,\n          partitions: partitions\n            .filter(\n              partition =>\n                /**\n                 * When recovering from OffsetOutOfRange, each partition can recover\n                 * concurrently, which invalidates resolved and committed offsets as part\n                 * of the recovery mechanism (see OffsetManager.clearOffsets). In concurrent\n                 * scenarios this can initiate a new fetch with invalid offsets.\n                 *\n                 * This was further highlighted by https://github.com/tulios/kafkajs/pull/570,\n                 * which increased concurrency, making this more likely to happen.\n                 *\n                 * This is solved by only making requests for partitions with initialized offsets.\n                 *\n                 * See the following pull request which explains the context of the problem:\n                 * @issue https://github.com/tulios/kafkajs/pull/578\n                 */\n                committedOffsets[topic][partition] != null &&\n                activeTopicPartitions[topic].has(partition)\n            )\n            .map(partition => ({\n              partition,\n              fetchOffset: this.offsetManager.nextOffset(topic, partition).toString(),\n              maxBytes: this.maxBytesPerPartition,\n            })),\n        }))\n        .filter(({ partitions }) => partitions.length)\n\n      if (!requests.length) {\n        await sleep(this.maxWaitTime)\n        return []\n      }\n\n      const broker = await this.cluster.findBroker({ nodeId })\n\n      const { responses } = await broker.fetch({\n        maxWaitTime: this.maxWaitTime,\n        minBytes: this.minBytes,\n        maxBytes: this.maxBytes,\n        isolationLevel: this.isolationLevel,\n        topics: requests,\n        rackId: this.rackId,\n      })\n\n      return responses.flatMap(({ topicName, partitions }) => {\n        const topicRequestData = requests.find(({ topic }) => topic === topicName)\n\n        let preferredReadReplicas = this.preferredReadReplicasPerTopicPartition[topicName]\n        if (!preferredReadReplicas) {\n          this.preferredReadReplicasPerTopicPartition[topicName] = preferredReadReplicas = {}\n        }\n\n        return partitions\n          .filter(\n            ({ partition }) =>\n              !this.seekOffset.has(topicName, partition) &&\n              !this.subscriptionState.isPaused(topicName, partition)\n          )\n          .map(partitionData => {\n            const { partition, preferredReadReplica } = partitionData\n\n            if (preferredReadReplica != null && preferredReadReplica !== -1) {\n              const { nodeId: currentPreferredReadReplica } = preferredReadReplicas[partition] || {}\n              if (currentPreferredReadReplica !== preferredReadReplica) {\n                this.logger.info(`Preferred read replica is now ${preferredReadReplica}`, {\n                  groupId: this.groupId,\n                  memberId: this.memberId,\n                  topic: topicName,\n                  partition,\n                })\n              }\n              preferredReadReplicas[partition] = {\n                nodeId: preferredReadReplica,\n                expireAt: Date.now() + this.metadataMaxAge,\n              }\n            }\n\n            const partitionRequestData = topicRequestData.partitions.find(\n              ({ partition }) => partition === partitionData.partition\n            )\n\n            const fetchedOffset = partitionRequestData.fetchOffset\n            return new Batch(topicName, fetchedOffset, partitionData)\n          })\n      })\n    } catch (e) {\n      await this.recoverFromFetch(e)\n      return []\n    }\n  }\n\n  async recoverFromFetch(e) {\n    if (STALE_METADATA_ERRORS.includes(e.type) || e.name === 'KafkaJSTopicMetadataNotLoaded') {\n      this.logger.debug('Stale cluster metadata, refreshing...', {\n        groupId: this.groupId,\n        memberId: this.memberId,\n        error: e.message,\n      })\n\n      await this.cluster.refreshMetadata()\n      await this.joinAndSync()\n      return\n    }\n\n    if (e.name === 'KafkaJSStaleTopicMetadataAssignment') {\n      this.logger.warn(`${e.message}, resync group`, {\n        groupId: this.groupId,\n        memberId: this.memberId,\n        topic: e.topic,\n        unknownPartitions: e.unknownPartitions,\n      })\n\n      await this.joinAndSync()\n      return\n    }\n\n    if (e.name === 'KafkaJSOffsetOutOfRange') {\n      await this.recoverFromOffsetOutOfRange(e)\n      return\n    }\n\n    if (e.name === 'KafkaJSConnectionClosedError') {\n      this.cluster.removeBroker({ host: e.host, port: e.port })\n      return\n    }\n\n    if (e.name === 'KafkaJSBrokerNotFound' || e.name === 'KafkaJSConnectionClosedError') {\n      this.logger.debug(`${e.message}, refreshing metadata and retrying...`)\n      await this.cluster.refreshMetadata()\n      return\n    }\n\n    throw e\n  }\n\n  async recoverFromOffsetOutOfRange(e) {\n    // If we are fetching from a follower try with the leader before resetting offsets\n    const preferredReadReplicas = this.preferredReadReplicasPerTopicPartition[e.topic]\n    if (preferredReadReplicas && typeof preferredReadReplicas[e.partition] === 'number') {\n      this.logger.info('Offset out of range while fetching from follower, retrying with leader', {\n        topic: e.topic,\n        partition: e.partition,\n        groupId: this.groupId,\n        memberId: this.memberId,\n      })\n      delete preferredReadReplicas[e.partition]\n    } else {\n      this.logger.error('Offset out of range, resetting to default offset', {\n        topic: e.topic,\n        partition: e.partition,\n        groupId: this.groupId,\n        memberId: this.memberId,\n      })\n\n      await this.offsetManager.setDefaultOffset({\n        topic: e.topic,\n        partition: e.partition,\n      })\n    }\n  }\n\n  generatePartitionsPerSubscribedTopic() {\n    const map = new Map()\n\n    for (const topic of this.topicsSubscribed) {\n      const partitions = this.cluster\n        .findTopicPartitionMetadata(topic)\n        .map(m => m.partitionId)\n        .sort()\n\n      map.set(topic, partitions)\n    }\n\n    return map\n  }\n\n  checkForStaleAssignment() {\n    if (!this.partitionsPerSubscribedTopic) {\n      return\n    }\n\n    const newPartitionsPerSubscribedTopic = this.generatePartitionsPerSubscribedTopic()\n\n    for (const [topic, partitions] of newPartitionsPerSubscribedTopic) {\n      const diff = arrayDiff(partitions, this.partitionsPerSubscribedTopic.get(topic))\n\n      if (diff.length > 0) {\n        throw new KafkaJSStaleTopicMetadataAssignment('Topic has been updated', {\n          topic,\n          unknownPartitions: diff,\n        })\n      }\n    }\n  }\n\n  async seekOffsets(topicPartitions) {\n    for (const { topic, partitions } of topicPartitions) {\n      for (const partition of partitions) {\n        const seekEntry = this.seekOffset.pop(topic, partition)\n        if (!seekEntry) {\n          continue\n        }\n\n        this.logger.debug('Seek offset', {\n          groupId: this.groupId,\n          memberId: this.memberId,\n          seek: seekEntry,\n        })\n        await this.offsetManager.seek(seekEntry)\n      }\n    }\n\n    await this.offsetManager.resolveOffsets()\n  }\n\n  hasSeekOffset({ topic, partition }) {\n    return this.seekOffset.has(topic, partition)\n  }\n\n  /**\n   * For each of the partitions find the best nodeId to read it from\n   *\n   * @param {string} topic\n   * @param {number[]} partitions\n   * @returns {{[nodeId: number]: number[]}} per-node assignment of partitions\n   * @see Cluster~findLeaderForPartitions\n   */\n  // Invariant: The resulting object has each partition referenced exactly once\n  findReadReplicaForPartitions(topic, partitions) {\n    const partitionMetadata = this.cluster.findTopicPartitionMetadata(topic)\n    const preferredReadReplicas = this.preferredReadReplicasPerTopicPartition[topic]\n    return partitions.reduce((result, id) => {\n      const partitionId = parseInt(id, 10)\n      const metadata = partitionMetadata.find(p => p.partitionId === partitionId)\n      if (!metadata) {\n        return result\n      }\n\n      if (metadata.leader == null) {\n        throw new KafkaJSError('Invalid partition metadata', { topic, partitionId, metadata })\n      }\n\n      // Pick the preferred replica if there is one, and it isn't known to be offline, otherwise the leader.\n      let nodeId = metadata.leader\n      if (preferredReadReplicas) {\n        const { nodeId: preferredReadReplica, expireAt } = preferredReadReplicas[partitionId] || {}\n        if (Date.now() >= expireAt) {\n          this.logger.debug('Preferred read replica information has expired, using leader', {\n            topic,\n            partitionId,\n            groupId: this.groupId,\n            memberId: this.memberId,\n            preferredReadReplica,\n            leader: metadata.leader,\n          })\n          // Drop the entry\n          delete preferredReadReplicas[partitionId]\n        } else if (preferredReadReplica != null) {\n          // Valid entry, check whether it is not offline\n          // Note that we don't delete the preference here, and rather hope that eventually that replica comes online again\n          const offlineReplicas = metadata.offlineReplicas\n          if (Array.isArray(offlineReplicas) && offlineReplicas.includes(nodeId)) {\n            this.logger.debug('Preferred read replica is offline, using leader', {\n              topic,\n              partitionId,\n              groupId: this.groupId,\n              memberId: this.memberId,\n              preferredReadReplica,\n              leader: metadata.leader,\n            })\n          } else {\n            nodeId = preferredReadReplica\n          }\n        }\n      }\n      const current = result[nodeId] || []\n      return { ...result, [nodeId]: [...current, partitionId] }\n    }, {})\n  }\n\n  filterPartitionsByNode(nodeId, topicPartitions) {\n    return topicPartitions.map(({ topic, partitions }) => ({\n      topic,\n      partitions: this.findReadReplicaForPartitions(topic, partitions)[nodeId] || [],\n    }))\n  }\n\n  getActiveTopicPartitions() {\n    const activeSubscriptionState = this.subscriptionState.active()\n\n    const activeTopicPartitions = {}\n    activeSubscriptionState.forEach(({ topic, partitions }) => {\n      activeTopicPartitions[topic] = new Set(partitions)\n    })\n\n    return activeTopicPartitions\n  }\n}\n"],"mappings":";AAAA,MAAMA,KAAK,GAAGC,OAAO,CAAC,gBAAgB,CAAC;AACvC,MAAMC,UAAU,GAAGD,OAAO,CAAC,qBAAqB,CAAC;AACjD,MAAME,SAAS,GAAGF,OAAO,CAAC,oBAAoB,CAAC;AAC/C,MAAMG,WAAW,GAAGH,OAAO,CAAC,UAAU,CAAC;AACvC,MAAMI,eAAe,GAAGJ,OAAO,CAAC,0BAA0B,CAAC;AAE3D,MAAMK,aAAa,GAAGL,OAAO,CAAC,iBAAiB,CAAC;AAChD,MAAMM,KAAK,GAAGN,OAAO,CAAC,SAAS,CAAC;AAChC,MAAMO,WAAW,GAAGP,OAAO,CAAC,eAAe,CAAC;AAC5C,MAAMQ,iBAAiB,GAAGR,OAAO,CAAC,qBAAqB,CAAC;AACxD,MAAM;EACJS,MAAM,EAAE;IAAEC,UAAU;IAAEC,SAAS;IAAEC,OAAO;IAAEC;EAA6B;AACzE,CAAC,GAAGb,OAAO,CAAC,yBAAyB,CAAC;AACtC,MAAM;EAAEc;AAAiB,CAAC,GAAGd,OAAO,CAAC,oBAAoB,CAAC;AAC1D,MAAM;EACJe,YAAY;EACZC,wBAAwB;EACxBC,mCAAmC;EACnCC;AACF,CAAC,GAAGlB,OAAO,CAAC,WAAW,CAAC;AAExB,MAAM;EAAEmB;AAAK,CAAC,GAAGC,MAAM;AAEvB,MAAMC,qBAAqB,GAAG,CAC5B,sBAAsB;AACtB;AACA,0BAA0B;AAC1B;AACA,qBAAqB,EACrB,sBAAsB,EACtB,4BAA4B,CAC7B;AAED,MAAMC,OAAO,GAAG;EACdC,IAAI,EAAEC,MAAM,CAAC,4BAA4B,CAAC;EAC1CC,IAAI,EAAED,MAAM,CAAC,4BAA4B,CAAC;EAC1CE,gBAAgB,EAAEF,MAAM,CAAC,uCAAuC;AAClE,CAAC;AAEDG,MAAM,CAACC,OAAO,GAAG,MAAMC,aAAa,CAAC;EACnC;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACEC,WAAW,CAAC;IACVC,KAAK;IACLC,OAAO;IACPC,OAAO;IACPC,MAAM;IACNC,mBAAmB;IACnBC,MAAM;IACNC,sBAAsB;IACtBC,SAAS;IACTC,cAAc;IACdC,gBAAgB;IAChBC,oBAAoB;IACpBC,QAAQ;IACRC,QAAQ;IACRC,eAAe;IACfC,UAAU;IACVC,kBAAkB;IAClBC,mBAAmB;IACnBC,cAAc;IACdC,MAAM;IACNC;EACF,CAAC,EAAE;IAAA;IACD;IACA,IAAI,CAAClB,OAAO,GAAGA,OAAO;IACtB,IAAI,CAACC,OAAO,GAAGA,OAAO;IACtB,IAAI,CAACC,MAAM,GAAGA,MAAM;IACpB,IAAI,CAACiB,gBAAgB,GAAGjB,MAAM;IAC9B,IAAI,CAACC,mBAAmB,GAAGA,mBAAmB;IAC9C,IAAI,CAACC,MAAM,GAAGA,MAAM,CAACgB,SAAS,CAAC,eAAe,CAAC;IAC/C,IAAI,CAACf,sBAAsB,GAAGA,sBAAsB;IACpD,IAAI,CAACgB,OAAO,GAAGlD,WAAW,CAACiB,MAAM,CAACkC,MAAM,CAAC,CAAC,CAAC,EAAEvB,KAAK,CAAC,CAAC;IACpD,IAAI,CAACO,SAAS,GAAGA,SAAS;IAC1B,IAAI,CAACC,cAAc,GAAGA,cAAc;IACpC,IAAI,CAACC,gBAAgB,GAAGA,gBAAgB;IACxC,IAAI,CAACC,oBAAoB,GAAGA,oBAAoB;IAChD,IAAI,CAACC,QAAQ,GAAGA,QAAQ;IACxB,IAAI,CAACC,QAAQ,GAAGA,QAAQ;IACxB,IAAI,CAACY,WAAW,GAAGX,eAAe;IAClC,IAAI,CAACC,UAAU,GAAGA,UAAU;IAC5B,IAAI,CAACC,kBAAkB,GAAGA,kBAAkB;IAC5C,IAAI,CAACC,mBAAmB,GAAGA,mBAAmB;IAC9C,IAAI,CAACC,cAAc,GAAGA,cAAc;IACpC,IAAI,CAACC,MAAM,GAAGA,MAAM;IACpB,IAAI,CAACC,cAAc,GAAGA,cAAc;IAEpC,IAAI,CAACM,UAAU,GAAG,IAAIjD,WAAW,EAAE;IACnC,IAAI,CAACkD,WAAW,GAAG,IAAI;IACvB,IAAI,CAACC,YAAY,GAAG,IAAI;IACxB,IAAI,CAACC,QAAQ,GAAG,IAAI;IACpB,IAAI,CAACC,QAAQ,GAAG,IAAI;IACpB,IAAI,CAACC,OAAO,GAAG,IAAI;IACnB,IAAI,CAACC,aAAa,GAAG,IAAI;IAEzB,IAAI,CAACC,4BAA4B,GAAG,IAAI;IACxC;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;IACI,IAAI,CAACC,sCAAsC,GAAG,CAAC,CAAC;IAChD,IAAI,CAACC,aAAa,GAAG,IAAI;IACzB,IAAI,CAACC,iBAAiB,GAAG,IAAI1D,iBAAiB,EAAE;IAEhD,IAAI,CAAC2D,WAAW,GAAGC,IAAI,CAACC,GAAG,EAAE;IAE7B,IAAI,CAAC/C,OAAO,CAACI,gBAAgB,CAAC,GAAGtB,eAAe;MAAA,6BAAC,WAAO;QAAEkE;MAAS,CAAC,EAAK;QACvE,MAAM;UAAErC,OAAO;UAAEyB,YAAY;UAAEE;QAAS,CAAC,GAAG,KAAI;QAChD,MAAMS,GAAG,GAAGD,IAAI,CAACC,GAAG,EAAE;QAEtB,IAAIT,QAAQ,IAAIS,GAAG,IAAI,KAAI,CAACF,WAAW,GAAGG,QAAQ,EAAE;UAClD,MAAMC,OAAO,GAAG;YACdtC,OAAO;YACP2B,QAAQ;YACRY,iBAAiB,EAAEd;UACrB,CAAC;UAED,MAAM,KAAI,CAACD,WAAW,CAACgB,SAAS,CAACF,OAAO,CAAC;UACzC,KAAI,CAAClC,sBAAsB,CAACqC,IAAI,CAAC/D,SAAS,EAAE4D,OAAO,CAAC;UACpD,KAAI,CAACJ,WAAW,GAAGC,IAAI,CAACC,GAAG,EAAE;QAC/B;MACF,CAAC;MAAA;QAAA;MAAA;IAAA,IAAC;EACJ;EAEAM,QAAQ,GAAG;IACT,OAAO,IAAI,CAAChB,QAAQ,IAAI,IAAI,CAACC,QAAQ,KAAK,IAAI,CAACD,QAAQ;EACzD;EAEAiB,UAAU,GAAG;IACX,OAAO,IAAI,CAAC5C,OAAO,CAAC4C,UAAU,EAAE;EAClC;EAEMC,OAAO,GAAG;IAAA;IAAA;MACd,MAAM,MAAI,CAAC7C,OAAO,CAAC6C,OAAO,EAAE;MAC5B,MAAI,CAACxC,sBAAsB,CAACqC,IAAI,CAAC9D,OAAO,CAAC;MACzC,MAAM,MAAI,CAACoB,OAAO,CAAC8C,0BAA0B,EAAE;IAAA;EACjD;EAEA,CAAOxD,OAAO,CAACC,IAAI,IAAI;IAAA;IAAA;MACrB,MAAM;QAAEU,OAAO;QAAEM,cAAc;QAAEC;MAAiB,CAAC,GAAG,MAAI;MAE1D,MAAI,CAACiB,WAAW,SAAS,MAAI,CAACzB,OAAO,CAAC+C,oBAAoB,CAAC;QAAE9C;MAAQ,CAAC,CAAC;MAEvE,MAAM+C,SAAS,SAAS,MAAI,CAACvB,WAAW,CAACwB,SAAS,CAAC;QACjDhD,OAAO;QACPM,cAAc;QACdC,gBAAgB;QAChBoB,QAAQ,EAAE,MAAI,CAACA,QAAQ,IAAI,EAAE;QAC7BsB,cAAc,EAAE,MAAI,CAAC5C,SAAS,CAAC6C,GAAG,CAACC,QAAQ,IACzCA,QAAQ,CAACC,QAAQ,CAAC;UAChBnD,MAAM,EAAE,MAAI,CAACiB;QACf,CAAC,CAAC;MAEN,CAAC,CAAC;MAEF,MAAI,CAACO,YAAY,GAAGsB,SAAS,CAACtB,YAAY;MAC1C,MAAI,CAACC,QAAQ,GAAGqB,SAAS,CAACrB,QAAQ;MAClC,MAAI,CAACC,QAAQ,GAAGoB,SAAS,CAACpB,QAAQ;MAClC,MAAI,CAACC,OAAO,GAAGmB,SAAS,CAACnB,OAAO;MAChC,MAAI,CAACC,aAAa,GAAGkB,SAAS,CAAClB,aAAa;IAAA;EAC9C;EAEMwB,KAAK,GAAG;IAAA;IAAA;MACZ,MAAM;QAAErD,OAAO;QAAE2B;MAAS,CAAC,GAAG,MAAI;MAClC,IAAIA,QAAQ,EAAE;QACZ,MAAM,MAAI,CAACH,WAAW,CAAC8B,UAAU,CAAC;UAAEtD,OAAO;UAAE2B;QAAS,CAAC,CAAC;QACxD,MAAI,CAACA,QAAQ,GAAG,IAAI;MACtB;IAAC;EACH;EAEA,CAAOtC,OAAO,CAACG,IAAI,IAAI;IAAA;IAAA;MACrB,IAAI+D,UAAU,GAAG,EAAE;MACnB,MAAM;QACJvD,OAAO;QACPyB,YAAY;QACZE,QAAQ;QACRC,OAAO;QACPC,aAAa;QACb5B,MAAM;QACNiB,gBAAgB;QAChBM;MACF,CAAC,GAAG,MAAI;MAER,IAAI,MAAI,CAACkB,QAAQ,EAAE,EAAE;QACnB,MAAI,CAACvC,MAAM,CAACqD,KAAK,CAAC,wBAAwB,EAAE;UAAExD,OAAO;UAAEyB,YAAY;UAAEE,QAAQ;UAAE1B;QAAO,CAAC,CAAC;QACxF,MAAMkD,QAAQ,GAAG,MAAI,CAAC9C,SAAS,CAACoD,IAAI,CAAC,CAAC;UAAEC;QAAK,CAAC,KAAKA,IAAI,KAAK7B,aAAa,CAAC;QAE1E,IAAI,CAACsB,QAAQ,EAAE;UACb,MAAM,IAAIpE,wBAAwB,CAC/B,mCAAkC8C,aAAc,oDAAmD,CACrG;QACH;QAEA,MAAM,MAAI,CAAC9B,OAAO,CAAC4D,eAAe,EAAE;QACpCJ,UAAU,SAASJ,QAAQ,CAAC9B,MAAM,CAAC;UAAEO,OAAO;UAAE3B,MAAM,EAAEiB;QAAiB,CAAC,CAAC;QAEzE,MAAI,CAACf,MAAM,CAACqD,KAAK,CAAC,kBAAkB,EAAE;UACpCxD,OAAO;UACPyB,YAAY;UACZI,aAAa;UACb0B,UAAU;UACVtD,MAAM,EAAEiB;QACV,CAAC,CAAC;MACJ;;MAEA;MACA,MAAI,CAACY,4BAA4B,GAAG,MAAI,CAAC8B,oCAAoC,EAAE;MAC/E,MAAM;QAAEC;MAAiB,CAAC,SAAS,MAAI,CAACrC,WAAW,CAACsC,SAAS,CAAC;QAC5D9D,OAAO;QACPyB,YAAY;QACZE,QAAQ;QACRoC,eAAe,EAAER;MACnB,CAAC,CAAC;MAEF,MAAMS,uBAAuB,GAAGnF,gBAAgB,CAACoF,MAAM,CAACJ,gBAAgB,CAAC;MACzE,MAAMK,iBAAiB,GACrBF,uBAAuB,IAAI,IAAI,GAAGA,uBAAuB,CAACT,UAAU,GAAG,CAAC,CAAC;MAE3E,MAAI,CAACpD,MAAM,CAACqD,KAAK,CAAC,qBAAqB,EAAE;QACvCxD,OAAO;QACPyB,YAAY;QACZE,QAAQ;QACRkC,gBAAgB,EAAEK;MACpB,CAAC,CAAC;MAEF,MAAMC,cAAc,GAAGjF,IAAI,CAACgF,iBAAiB,CAAC;MAC9C,MAAME,mBAAmB,GAAGnG,SAAS,CAACkG,cAAc,EAAEjD,gBAAgB,CAAC;MAEvE,IAAIkD,mBAAmB,CAACC,MAAM,GAAG,CAAC,EAAE;QAClC,MAAM/B,OAAO,GAAG;UACdtC,OAAO;UACPyB,YAAY;UACZE,QAAQ;UACRwC,cAAc;UACdjD,gBAAgB;UAChBkD;QACF,CAAC;QAED,MAAI,CAAChE,sBAAsB,CAACqC,IAAI,CAAC7D,4BAA4B,EAAE0D,OAAO,CAAC;QACvE,MAAI,CAACnC,MAAM,CAACmE,IAAI,CAAC,6CAA6C,EAAE;UAC9D,GAAGhC,OAAO;UACViC,OAAO,EAAEvG,UAAU,CACjB,UAAU,EACV,8DAA8D;QAElE,CAAC,CAAC;MACJ;;MAEA;MACA,MAAMwG,cAAc,GAAGvG,SAAS,CAACkG,cAAc,EAAEC,mBAAmB,CAAC;MACrE,MAAMK,uBAAuB,GAAGD,cAAc,CAACtB,GAAG,CAACwB,KAAK,KAAK;QAC3DA,KAAK;QACLC,UAAU,EAAET,iBAAiB,CAACQ,KAAK;MACrC,CAAC,CAAC,CAAC;;MAEH;MACA,KAAK,MAAMnB,UAAU,IAAIkB,uBAAuB,EAAE;QAChD,MAAM;UAAEC,KAAK;UAAEC,UAAU,EAAEC;QAAmB,CAAC,GAAGrB,UAAU;QAC5D,MAAMsB,eAAe,GAAG,MAAI,CAAC/C,4BAA4B,CAACgD,GAAG,CAACJ,KAAK,CAAC;QACpE,MAAMK,8BAA8B,GAAGH,kBAAkB,CAACI,KAAK,CAACC,SAAS,IACvEJ,eAAe,CAACK,QAAQ,CAACD,SAAS,CAAC,CACpC;QAED,IAAI,CAACF,8BAA8B,EAAE;UACnC,MAAI,CAAC5E,MAAM,CAACmE,IAAI,CAAC,uEAAuE,EAAE;YACxFtE,OAAO;YACPyB,YAAY;YACZE,QAAQ;YACR+C,KAAK;YACLG,eAAe;YACfD;UACF,CAAC,CAAC;;UAEF;UACA;UACA;UACA,MAAM,MAAI,CAAC7E,OAAO,CAAC4D,eAAe,EAAE;UACpC,MAAI,CAAC7B,4BAA4B,GAAG,MAAI,CAAC8B,oCAAoC,EAAE;UAC/E;QACF;MACF;MAEA,MAAI,CAAC3D,MAAM,GAAGwE,uBAAuB,CAACvB,GAAG,CAAC,CAAC;QAAEwB;MAAM,CAAC,KAAKA,KAAK,CAAC;MAC/D,MAAI,CAACzC,iBAAiB,CAACZ,MAAM,CAACoD,uBAAuB,CAAC;MACtD,MAAI,CAACzC,aAAa,GAAG,IAAI5D,aAAa,CAAC;QACrC2B,OAAO,EAAE,MAAI,CAACA,OAAO;QACrBG,mBAAmB,EAAE,MAAI,CAACA,mBAAmB;QAC7CE,sBAAsB,EAAE,MAAI,CAACA,sBAAsB;QACnDyD,gBAAgB,EAAEY,uBAAuB,CAACU,MAAM,CAC9C,CAACC,iBAAiB,EAAE;UAAEV,KAAK;UAAEC;QAAW,CAAC,MAAM;UAC7C,GAAGS,iBAAiB;UACpB,CAACV,KAAK,GAAGC;QACX,CAAC,CAAC,EACF,CAAC,CAAC,CACH;QACD/D,UAAU,EAAE,MAAI,CAACA,UAAU;QAC3BC,kBAAkB,EAAE,MAAI,CAACA,kBAAkB;QAC3CC,mBAAmB,EAAE,MAAI,CAACA,mBAAmB;QAC7CU,WAAW;QACXxB,OAAO;QACPyB,YAAY;QACZE;MACF,CAAC,CAAC;IAAA;EACJ;EAEA0D,WAAW,GAAG;IAAA;IACZ,MAAMC,SAAS,GAAGnD,IAAI,CAACC,GAAG,EAAE;IAC5B,OAAO,IAAI,CAAChB,OAAO;MAAA,8BAAC,WAAMmE,IAAI,EAAI;QAChC,IAAI;UACF,MAAM,MAAI,CAAClG,OAAO,CAACC,IAAI,CAAC,EAAE;UAC1B,MAAM,MAAI,CAACD,OAAO,CAACG,IAAI,CAAC,EAAE;UAE1B,MAAMqE,gBAAgB,GAAG,MAAI,CAAC2B,QAAQ,EAAE,CAACL,MAAM,CAC7C,CAACM,MAAM,EAAE;YAAEf,KAAK;YAAEC;UAAW,CAAC,MAAM;YAAE,GAAGc,MAAM;YAAE,CAACf,KAAK,GAAGC;UAAW,CAAC,CAAC,EACvE,CAAC,CAAC,CACH;UAED,MAAMrC,OAAO,GAAG;YACdtC,OAAO,EAAE,MAAI,CAACA,OAAO;YACrB2B,QAAQ,EAAE,MAAI,CAACA,QAAQ;YACvBD,QAAQ,EAAE,MAAI,CAACA,QAAQ;YACvBgB,QAAQ,EAAE,MAAI,CAACA,QAAQ,EAAE;YACzBmB,gBAAgB;YAChBhC,aAAa,EAAE,MAAI,CAACA,aAAa;YACjC6D,QAAQ,EAAEvD,IAAI,CAACC,GAAG,EAAE,GAAGkD;UACzB,CAAC;UAED,MAAI,CAAClF,sBAAsB,CAACqC,IAAI,CAAChE,UAAU,EAAE6D,OAAO,CAAC;UACrD,MAAI,CAACnC,MAAM,CAACwF,IAAI,CAAC,+BAA+B,EAAErD,OAAO,CAAC;QAC5D,CAAC,CAAC,OAAOsD,CAAC,EAAE;UACV,IAAI3G,aAAa,CAAC2G,CAAC,CAAC,EAAE;YACpB;YACA;YACA;YACA;YACA,MAAM,IAAI9G,YAAY,CAAC8G,CAAC,CAAC;UAC3B;UAEA,IAAIA,CAAC,CAACC,IAAI,KAAK,mBAAmB,EAAE;YAClC,MAAI,CAAClE,QAAQ,GAAG,IAAI;YACpB,MAAM,IAAI7C,YAAY,CAAC8G,CAAC,CAAC;UAC3B;UAEAL,IAAI,CAACK,CAAC,CAAC;QACT;MACF,CAAC;MAAA;QAAA;MAAA;IAAA,IAAC;EACJ;;EAEA;AACF;AACA;EACEE,WAAW,CAAC;IAAEpB,KAAK;IAAEO;EAAU,CAAC,EAAE;IAChC,IAAI,CAACjD,aAAa,CAAC8D,WAAW,CAAC;MAAEpB,KAAK;MAAEO;IAAU,CAAC,CAAC;EACtD;;EAEA;AACF;AACA;EACEc,aAAa,CAAC;IAAErB,KAAK;IAAEO,SAAS;IAAEe;EAAO,CAAC,EAAE;IAC1C,IAAI,CAAChE,aAAa,CAAC+D,aAAa,CAAC;MAAErB,KAAK;MAAEO,SAAS;MAAEe;IAAO,CAAC,CAAC;EAChE;;EAEA;AACF;AACA;AACA;AACA;AACA;AACA;EACEC,IAAI,CAAC;IAAEvB,KAAK;IAAEO,SAAS;IAAEe;EAAO,CAAC,EAAE;IACjC,IAAI,CAACzE,UAAU,CAAC2E,GAAG,CAACxB,KAAK,EAAEO,SAAS,EAAEe,MAAM,CAAC;EAC/C;EAEAG,KAAK,CAACC,eAAe,EAAE;IACrB,IAAI,CAACjG,MAAM,CAACwF,IAAI,CAAE,yBAAwBS,eAAe,CAAC/B,MAAO,SAAQ,EAAE;MACzE+B;IACF,CAAC,CAAC;IACF,IAAI,CAACnE,iBAAiB,CAACkE,KAAK,CAACC,eAAe,CAAC;EAC/C;EAEAC,MAAM,CAACD,eAAe,EAAE;IACtB,IAAI,CAACjG,MAAM,CAACwF,IAAI,CAAE,0BAAyBS,eAAe,CAAC/B,MAAO,SAAQ,EAAE;MAC1E+B;IACF,CAAC,CAAC;IACF,IAAI,CAACnE,iBAAiB,CAACoE,MAAM,CAACD,eAAe,CAAC;EAChD;EAEAZ,QAAQ,GAAG;IACT,OAAO,IAAI,CAACvD,iBAAiB,CAACuD,QAAQ,EAAE;EAC1C;EAEAc,MAAM,GAAG;IACP,OAAO,IAAI,CAACrE,iBAAiB,CAACqE,MAAM,EAAE;EACxC;;EAEA;AACF;AACA;AACA;AACA;EACEC,QAAQ,CAAC7B,KAAK,EAAEO,SAAS,EAAE;IACzB,OAAO,IAAI,CAAChD,iBAAiB,CAACsE,QAAQ,CAAC7B,KAAK,EAAEO,SAAS,CAAC;EAC1D;EAEMuB,wBAAwB,GAAG;IAAA;IAAA;MAC/B,MAAM,MAAI,CAACxE,aAAa,CAACwE,wBAAwB,EAAE;IAAA;EACrD;EAEMC,aAAa,CAACC,OAAO,EAAE;IAAA;IAAA;MAC3B,MAAM,MAAI,CAAC1E,aAAa,CAACyE,aAAa,CAACC,OAAO,CAAC;IAAA;EACjD;EAEAC,kBAAkB,GAAG;IACnB,OAAO,IAAI,CAAC3E,aAAa,CAAC2E,kBAAkB,EAAE;EAChD;EAEMnE,SAAS,CAAC;IAAEH;EAAS,CAAC,EAAE;IAAA;IAAA;MAC5B,OAAO,MAAI,CAAChD,OAAO,CAACI,gBAAgB,CAAC,CAAC;QAAE4C;MAAS,CAAC,CAAC;IAAA;EACrD;EAEMuE,KAAK,CAACC,MAAM,EAAE;IAAA;IAAA;MAClB,IAAI;QACF,MAAM,OAAI,CAAC9G,OAAO,CAAC8C,0BAA0B,EAAE;QAC/C,OAAI,CAACiE,uBAAuB,EAAE;QAE9B,IAAIV,eAAe,GAAG,OAAI,CAACnE,iBAAiB,CAACuD,QAAQ,EAAE;QACvDY,eAAe,GAAG,OAAI,CAACW,sBAAsB,CAACF,MAAM,EAAET,eAAe,CAAC;QAEtE,MAAM,OAAI,CAACY,WAAW,CAACZ,eAAe,CAAC;QAEvC,MAAMa,gBAAgB,GAAG,OAAI,CAACjF,aAAa,CAACiF,gBAAgB,EAAE;QAC9D,MAAMC,qBAAqB,GAAG,OAAI,CAACC,wBAAwB,EAAE;QAE7D,MAAMC,QAAQ,GAAGhB,eAAe,CAC7BlD,GAAG,CAAC,CAAC;UAAEwB,KAAK;UAAEC;QAAW,CAAC,MAAM;UAC/BD,KAAK;UACLC,UAAU,EAAEA,UAAU,CACnB0C,MAAM,CACLpC,SAAS;UACP;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;UACgBgC,gBAAgB,CAACvC,KAAK,CAAC,CAACO,SAAS,CAAC,IAAI,IAAI,IAC1CiC,qBAAqB,CAACxC,KAAK,CAAC,CAAC4C,GAAG,CAACrC,SAAS,CAAC,CAC9C,CACA/B,GAAG,CAAC+B,SAAS,KAAK;YACjBA,SAAS;YACTsC,WAAW,EAAE,OAAI,CAACvF,aAAa,CAACwF,UAAU,CAAC9C,KAAK,EAAEO,SAAS,CAAC,CAACwC,QAAQ,EAAE;YACvE/G,QAAQ,EAAE,OAAI,CAACF;UACjB,CAAC,CAAC;QACN,CAAC,CAAC,CAAC,CACF6G,MAAM,CAAC,CAAC;UAAE1C;QAAW,CAAC,KAAKA,UAAU,CAACN,MAAM,CAAC;QAEhD,IAAI,CAAC+C,QAAQ,CAAC/C,MAAM,EAAE;UACpB,MAAMvG,KAAK,CAAC,OAAI,CAACwD,WAAW,CAAC;UAC7B,OAAO,EAAE;QACX;QAEA,MAAMoG,MAAM,SAAS,OAAI,CAAC3H,OAAO,CAAC4H,UAAU,CAAC;UAAEd;QAAO,CAAC,CAAC;QAExD,MAAM;UAAEe;QAAU,CAAC,SAASF,MAAM,CAACd,KAAK,CAAC;UACvCtF,WAAW,EAAE,OAAI,CAACA,WAAW;UAC7Bb,QAAQ,EAAE,OAAI,CAACA,QAAQ;UACvBC,QAAQ,EAAE,OAAI,CAACA,QAAQ;UACvBK,cAAc,EAAE,OAAI,CAACA,cAAc;UACnCd,MAAM,EAAEmH,QAAQ;UAChBpG,MAAM,EAAE,OAAI,CAACA;QACf,CAAC,CAAC;QAEF,OAAO4G,SAAS,CAACC,OAAO,CAAC,CAAC;UAAEC,SAAS;UAAEnD;QAAW,CAAC,KAAK;UACtD,MAAMoD,gBAAgB,GAAGX,QAAQ,CAAC3D,IAAI,CAAC,CAAC;YAAEiB;UAAM,CAAC,KAAKA,KAAK,KAAKoD,SAAS,CAAC;UAE1E,IAAIE,qBAAqB,GAAG,OAAI,CAACjG,sCAAsC,CAAC+F,SAAS,CAAC;UAClF,IAAI,CAACE,qBAAqB,EAAE;YAC1B,OAAI,CAACjG,sCAAsC,CAAC+F,SAAS,CAAC,GAAGE,qBAAqB,GAAG,CAAC,CAAC;UACrF;UAEA,OAAOrD,UAAU,CACd0C,MAAM,CACL,CAAC;YAAEpC;UAAU,CAAC,KACZ,CAAC,OAAI,CAAC1D,UAAU,CAAC+F,GAAG,CAACQ,SAAS,EAAE7C,SAAS,CAAC,IAC1C,CAAC,OAAI,CAAChD,iBAAiB,CAACsE,QAAQ,CAACuB,SAAS,EAAE7C,SAAS,CAAC,CACzD,CACA/B,GAAG,CAAC+E,aAAa,IAAI;YACpB,MAAM;cAAEhD,SAAS;cAAEiD;YAAqB,CAAC,GAAGD,aAAa;YAEzD,IAAIC,oBAAoB,IAAI,IAAI,IAAIA,oBAAoB,KAAK,CAAC,CAAC,EAAE;cAC/D,MAAM;gBAAErB,MAAM,EAAEsB;cAA4B,CAAC,GAAGH,qBAAqB,CAAC/C,SAAS,CAAC,IAAI,CAAC,CAAC;cACtF,IAAIkD,2BAA2B,KAAKD,oBAAoB,EAAE;gBACxD,OAAI,CAAC/H,MAAM,CAACwF,IAAI,CAAE,iCAAgCuC,oBAAqB,EAAC,EAAE;kBACxElI,OAAO,EAAE,OAAI,CAACA,OAAO;kBACrB2B,QAAQ,EAAE,OAAI,CAACA,QAAQ;kBACvB+C,KAAK,EAAEoD,SAAS;kBAChB7C;gBACF,CAAC,CAAC;cACJ;cACA+C,qBAAqB,CAAC/C,SAAS,CAAC,GAAG;gBACjC4B,MAAM,EAAEqB,oBAAoB;gBAC5BE,QAAQ,EAAEjG,IAAI,CAACC,GAAG,EAAE,GAAG,OAAI,CAACnB;cAC9B,CAAC;YACH;YAEA,MAAMoH,oBAAoB,GAAGN,gBAAgB,CAACpD,UAAU,CAAClB,IAAI,CAC3D,CAAC;cAAEwB;YAAU,CAAC,KAAKA,SAAS,KAAKgD,aAAa,CAAChD,SAAS,CACzD;YAED,MAAMqD,aAAa,GAAGD,oBAAoB,CAACd,WAAW;YACtD,OAAO,IAAIlJ,KAAK,CAACyJ,SAAS,EAAEQ,aAAa,EAAEL,aAAa,CAAC;UAC3D,CAAC,CAAC;QACN,CAAC,CAAC;MACJ,CAAC,CAAC,OAAOrC,CAAC,EAAE;QACV,MAAM,OAAI,CAAC2C,gBAAgB,CAAC3C,CAAC,CAAC;QAC9B,OAAO,EAAE;MACX;IAAC;EACH;EAEM2C,gBAAgB,CAAC3C,CAAC,EAAE;IAAA;IAAA;MACxB,IAAIxG,qBAAqB,CAAC8F,QAAQ,CAACU,CAAC,CAACC,IAAI,CAAC,IAAID,CAAC,CAAClC,IAAI,KAAK,+BAA+B,EAAE;QACxF,OAAI,CAACvD,MAAM,CAACqD,KAAK,CAAC,uCAAuC,EAAE;UACzDxD,OAAO,EAAE,OAAI,CAACA,OAAO;UACrB2B,QAAQ,EAAE,OAAI,CAACA,QAAQ;UACvB6G,KAAK,EAAE5C,CAAC,CAAC6C;QACX,CAAC,CAAC;QAEF,MAAM,OAAI,CAAC1I,OAAO,CAAC4D,eAAe,EAAE;QACpC,MAAM,OAAI,CAAC0B,WAAW,EAAE;QACxB;MACF;MAEA,IAAIO,CAAC,CAAClC,IAAI,KAAK,qCAAqC,EAAE;QACpD,OAAI,CAACvD,MAAM,CAACmE,IAAI,CAAE,GAAEsB,CAAC,CAAC6C,OAAQ,gBAAe,EAAE;UAC7CzI,OAAO,EAAE,OAAI,CAACA,OAAO;UACrB2B,QAAQ,EAAE,OAAI,CAACA,QAAQ;UACvB+C,KAAK,EAAEkB,CAAC,CAAClB,KAAK;UACdgE,iBAAiB,EAAE9C,CAAC,CAAC8C;QACvB,CAAC,CAAC;QAEF,MAAM,OAAI,CAACrD,WAAW,EAAE;QACxB;MACF;MAEA,IAAIO,CAAC,CAAClC,IAAI,KAAK,yBAAyB,EAAE;QACxC,MAAM,OAAI,CAACiF,2BAA2B,CAAC/C,CAAC,CAAC;QACzC;MACF;MAEA,IAAIA,CAAC,CAAClC,IAAI,KAAK,8BAA8B,EAAE;QAC7C,OAAI,CAAC3D,OAAO,CAAC6I,YAAY,CAAC;UAAEC,IAAI,EAAEjD,CAAC,CAACiD,IAAI;UAAEC,IAAI,EAAElD,CAAC,CAACkD;QAAK,CAAC,CAAC;QACzD;MACF;MAEA,IAAIlD,CAAC,CAAClC,IAAI,KAAK,uBAAuB,IAAIkC,CAAC,CAAClC,IAAI,KAAK,8BAA8B,EAAE;QACnF,OAAI,CAACvD,MAAM,CAACqD,KAAK,CAAE,GAAEoC,CAAC,CAAC6C,OAAQ,uCAAsC,CAAC;QACtE,MAAM,OAAI,CAAC1I,OAAO,CAAC4D,eAAe,EAAE;QACpC;MACF;MAEA,MAAMiC,CAAC;IAAA;EACT;EAEM+C,2BAA2B,CAAC/C,CAAC,EAAE;IAAA;IAAA;MACnC;MACA,MAAMoC,qBAAqB,GAAG,OAAI,CAACjG,sCAAsC,CAAC6D,CAAC,CAAClB,KAAK,CAAC;MAClF,IAAIsD,qBAAqB,IAAI,OAAOA,qBAAqB,CAACpC,CAAC,CAACX,SAAS,CAAC,KAAK,QAAQ,EAAE;QACnF,OAAI,CAAC9E,MAAM,CAACwF,IAAI,CAAC,wEAAwE,EAAE;UACzFjB,KAAK,EAAEkB,CAAC,CAAClB,KAAK;UACdO,SAAS,EAAEW,CAAC,CAACX,SAAS;UACtBjF,OAAO,EAAE,OAAI,CAACA,OAAO;UACrB2B,QAAQ,EAAE,OAAI,CAACA;QACjB,CAAC,CAAC;QACF,OAAOqG,qBAAqB,CAACpC,CAAC,CAACX,SAAS,CAAC;MAC3C,CAAC,MAAM;QACL,OAAI,CAAC9E,MAAM,CAACqI,KAAK,CAAC,kDAAkD,EAAE;UACpE9D,KAAK,EAAEkB,CAAC,CAAClB,KAAK;UACdO,SAAS,EAAEW,CAAC,CAACX,SAAS;UACtBjF,OAAO,EAAE,OAAI,CAACA,OAAO;UACrB2B,QAAQ,EAAE,OAAI,CAACA;QACjB,CAAC,CAAC;QAEF,MAAM,OAAI,CAACK,aAAa,CAAC+G,gBAAgB,CAAC;UACxCrE,KAAK,EAAEkB,CAAC,CAAClB,KAAK;UACdO,SAAS,EAAEW,CAAC,CAACX;QACf,CAAC,CAAC;MACJ;IAAC;EACH;EAEArB,oCAAoC,GAAG;IACrC,MAAMV,GAAG,GAAG,IAAI8F,GAAG,EAAE;IAErB,KAAK,MAAMtE,KAAK,IAAI,IAAI,CAACxD,gBAAgB,EAAE;MACzC,MAAMyD,UAAU,GAAG,IAAI,CAAC5E,OAAO,CAC5BkJ,0BAA0B,CAACvE,KAAK,CAAC,CACjCxB,GAAG,CAACgG,CAAC,IAAIA,CAAC,CAACC,WAAW,CAAC,CACvBC,IAAI,EAAE;MAETlG,GAAG,CAACgD,GAAG,CAACxB,KAAK,EAAEC,UAAU,CAAC;IAC5B;IAEA,OAAOzB,GAAG;EACZ;EAEA4D,uBAAuB,GAAG;IACxB,IAAI,CAAC,IAAI,CAAChF,4BAA4B,EAAE;MACtC;IACF;IAEA,MAAMuH,+BAA+B,GAAG,IAAI,CAACzF,oCAAoC,EAAE;IAEnF,KAAK,MAAM,CAACc,KAAK,EAAEC,UAAU,CAAC,IAAI0E,+BAA+B,EAAE;MACjE,MAAMC,IAAI,GAAGrL,SAAS,CAAC0G,UAAU,EAAE,IAAI,CAAC7C,4BAA4B,CAACgD,GAAG,CAACJ,KAAK,CAAC,CAAC;MAEhF,IAAI4E,IAAI,CAACjF,MAAM,GAAG,CAAC,EAAE;QACnB,MAAM,IAAIrF,mCAAmC,CAAC,wBAAwB,EAAE;UACtE0F,KAAK;UACLgE,iBAAiB,EAAEY;QACrB,CAAC,CAAC;MACJ;IACF;EACF;EAEMtC,WAAW,CAACZ,eAAe,EAAE;IAAA;IAAA;MACjC,KAAK,MAAM;QAAE1B,KAAK;QAAEC;MAAW,CAAC,IAAIyB,eAAe,EAAE;QACnD,KAAK,MAAMnB,SAAS,IAAIN,UAAU,EAAE;UAClC,MAAM4E,SAAS,GAAG,OAAI,CAAChI,UAAU,CAACiI,GAAG,CAAC9E,KAAK,EAAEO,SAAS,CAAC;UACvD,IAAI,CAACsE,SAAS,EAAE;YACd;UACF;UAEA,OAAI,CAACpJ,MAAM,CAACqD,KAAK,CAAC,aAAa,EAAE;YAC/BxD,OAAO,EAAE,OAAI,CAACA,OAAO;YACrB2B,QAAQ,EAAE,OAAI,CAACA,QAAQ;YACvBsE,IAAI,EAAEsD;UACR,CAAC,CAAC;UACF,MAAM,OAAI,CAACvH,aAAa,CAACiE,IAAI,CAACsD,SAAS,CAAC;QAC1C;MACF;MAEA,MAAM,OAAI,CAACvH,aAAa,CAACyH,cAAc,EAAE;IAAA;EAC3C;EAEAC,aAAa,CAAC;IAAEhF,KAAK;IAAEO;EAAU,CAAC,EAAE;IAClC,OAAO,IAAI,CAAC1D,UAAU,CAAC+F,GAAG,CAAC5C,KAAK,EAAEO,SAAS,CAAC;EAC9C;;EAEA;AACF;AACA;AACA;AACA;AACA;AACA;AACA;EACE;EACA0E,4BAA4B,CAACjF,KAAK,EAAEC,UAAU,EAAE;IAC9C,MAAMiF,iBAAiB,GAAG,IAAI,CAAC7J,OAAO,CAACkJ,0BAA0B,CAACvE,KAAK,CAAC;IACxE,MAAMsD,qBAAqB,GAAG,IAAI,CAACjG,sCAAsC,CAAC2C,KAAK,CAAC;IAChF,OAAOC,UAAU,CAACQ,MAAM,CAAC,CAACM,MAAM,EAAEoE,EAAE,KAAK;MACvC,MAAMV,WAAW,GAAGW,QAAQ,CAACD,EAAE,EAAE,EAAE,CAAC;MACpC,MAAME,QAAQ,GAAGH,iBAAiB,CAACnG,IAAI,CAACuG,CAAC,IAAIA,CAAC,CAACb,WAAW,KAAKA,WAAW,CAAC;MAC3E,IAAI,CAACY,QAAQ,EAAE;QACb,OAAOtE,MAAM;MACf;MAEA,IAAIsE,QAAQ,CAACE,MAAM,IAAI,IAAI,EAAE;QAC3B,MAAM,IAAInL,YAAY,CAAC,4BAA4B,EAAE;UAAE4F,KAAK;UAAEyE,WAAW;UAAEY;QAAS,CAAC,CAAC;MACxF;;MAEA;MACA,IAAIlD,MAAM,GAAGkD,QAAQ,CAACE,MAAM;MAC5B,IAAIjC,qBAAqB,EAAE;QACzB,MAAM;UAAEnB,MAAM,EAAEqB,oBAAoB;UAAEE;QAAS,CAAC,GAAGJ,qBAAqB,CAACmB,WAAW,CAAC,IAAI,CAAC,CAAC;QAC3F,IAAIhH,IAAI,CAACC,GAAG,EAAE,IAAIgG,QAAQ,EAAE;UAC1B,IAAI,CAACjI,MAAM,CAACqD,KAAK,CAAC,8DAA8D,EAAE;YAChFkB,KAAK;YACLyE,WAAW;YACXnJ,OAAO,EAAE,IAAI,CAACA,OAAO;YACrB2B,QAAQ,EAAE,IAAI,CAACA,QAAQ;YACvBuG,oBAAoB;YACpB+B,MAAM,EAAEF,QAAQ,CAACE;UACnB,CAAC,CAAC;UACF;UACA,OAAOjC,qBAAqB,CAACmB,WAAW,CAAC;QAC3C,CAAC,MAAM,IAAIjB,oBAAoB,IAAI,IAAI,EAAE;UACvC;UACA;UACA,MAAMgC,eAAe,GAAGH,QAAQ,CAACG,eAAe;UAChD,IAAIC,KAAK,CAACC,OAAO,CAACF,eAAe,CAAC,IAAIA,eAAe,CAAChF,QAAQ,CAAC2B,MAAM,CAAC,EAAE;YACtE,IAAI,CAAC1G,MAAM,CAACqD,KAAK,CAAC,iDAAiD,EAAE;cACnEkB,KAAK;cACLyE,WAAW;cACXnJ,OAAO,EAAE,IAAI,CAACA,OAAO;cACrB2B,QAAQ,EAAE,IAAI,CAACA,QAAQ;cACvBuG,oBAAoB;cACpB+B,MAAM,EAAEF,QAAQ,CAACE;YACnB,CAAC,CAAC;UACJ,CAAC,MAAM;YACLpD,MAAM,GAAGqB,oBAAoB;UAC/B;QACF;MACF;MACA,MAAMmC,OAAO,GAAG5E,MAAM,CAACoB,MAAM,CAAC,IAAI,EAAE;MACpC,OAAO;QAAE,GAAGpB,MAAM;QAAE,CAACoB,MAAM,GAAG,CAAC,GAAGwD,OAAO,EAAElB,WAAW;MAAE,CAAC;IAC3D,CAAC,EAAE,CAAC,CAAC,CAAC;EACR;EAEApC,sBAAsB,CAACF,MAAM,EAAET,eAAe,EAAE;IAC9C,OAAOA,eAAe,CAAClD,GAAG,CAAC,CAAC;MAAEwB,KAAK;MAAEC;IAAW,CAAC,MAAM;MACrDD,KAAK;MACLC,UAAU,EAAE,IAAI,CAACgF,4BAA4B,CAACjF,KAAK,EAAEC,UAAU,CAAC,CAACkC,MAAM,CAAC,IAAI;IAC9E,CAAC,CAAC,CAAC;EACL;EAEAM,wBAAwB,GAAG;IACzB,MAAMmD,uBAAuB,GAAG,IAAI,CAACrI,iBAAiB,CAACsI,MAAM,EAAE;IAE/D,MAAMrD,qBAAqB,GAAG,CAAC,CAAC;IAChCoD,uBAAuB,CAACE,OAAO,CAAC,CAAC;MAAE9F,KAAK;MAAEC;IAAW,CAAC,KAAK;MACzDuC,qBAAqB,CAACxC,KAAK,CAAC,GAAG,IAAI+F,GAAG,CAAC9F,UAAU,CAAC;IACpD,CAAC,CAAC;IAEF,OAAOuC,qBAAqB;EAC9B;AACF,CAAC"},"metadata":{},"sourceType":"script","externalDependencies":[]}