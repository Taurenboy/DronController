{"ast":null,"code":"var _asyncToGenerator = require(\"C:/Users/ingev/Documents/Desarrollo/Luna/DronController/AD_UI/node_modules/@babel/runtime/helpers/asyncToGenerator.js\").default;\nconst Decoder = require('../../decoder');\nconst {\n  KafkaJSPartialMessageError\n} = require('../../../errors');\nconst {\n  lookupCodecByAttributes\n} = require('../../message/compression');\nconst RecordDecoder = require('../record/v0/decoder');\nconst TimestampTypes = require('../../timestampTypes');\nconst TIMESTAMP_TYPE_FLAG_MASK = 0x8;\nconst TRANSACTIONAL_FLAG_MASK = 0x10;\nconst CONTROL_FLAG_MASK = 0x20;\n\n/**\n * v0\n * RecordBatch =>\n *  FirstOffset => int64\n *  Length => int32\n *  PartitionLeaderEpoch => int32\n *  Magic => int8\n *  CRC => int32\n *  Attributes => int16\n *  LastOffsetDelta => int32\n *  FirstTimestamp => int64\n *  MaxTimestamp => int64\n *  ProducerId => int64\n *  ProducerEpoch => int16\n *  FirstSequence => int32\n *  Records => [Record]\n */\n\nmodule.exports = /*#__PURE__*/function () {\n  var _ref = _asyncToGenerator(function* (fetchDecoder) {\n    const firstOffset = fetchDecoder.readInt64().toString();\n    const length = fetchDecoder.readInt32();\n    const decoder = fetchDecoder.slice(length);\n    fetchDecoder.forward(length);\n    const remainingBytes = Buffer.byteLength(decoder.buffer);\n    if (remainingBytes < length) {\n      throw new KafkaJSPartialMessageError(`Tried to decode a partial record batch: remainingBytes(${remainingBytes}) < recordBatchLength(${length})`);\n    }\n    const partitionLeaderEpoch = decoder.readInt32();\n\n    // The magic byte was read by the Fetch protocol to distinguish between\n    // the record batch and the legacy message set. It's not used here but\n    // it has to be read.\n    const magicByte = decoder.readInt8(); // eslint-disable-line no-unused-vars\n\n    // The library is currently not performing CRC validations\n    const crc = decoder.readInt32(); // eslint-disable-line no-unused-vars\n\n    const attributes = decoder.readInt16();\n    const lastOffsetDelta = decoder.readInt32();\n    const firstTimestamp = decoder.readInt64().toString();\n    const maxTimestamp = decoder.readInt64().toString();\n    const producerId = decoder.readInt64().toString();\n    const producerEpoch = decoder.readInt16();\n    const firstSequence = decoder.readInt32();\n    const inTransaction = (attributes & TRANSACTIONAL_FLAG_MASK) > 0;\n    const isControlBatch = (attributes & CONTROL_FLAG_MASK) > 0;\n    const timestampType = (attributes & TIMESTAMP_TYPE_FLAG_MASK) > 0 ? TimestampTypes.LOG_APPEND_TIME : TimestampTypes.CREATE_TIME;\n    const codec = lookupCodecByAttributes(attributes);\n    const recordContext = {\n      firstOffset,\n      firstTimestamp,\n      partitionLeaderEpoch,\n      inTransaction,\n      isControlBatch,\n      lastOffsetDelta,\n      producerId,\n      producerEpoch,\n      firstSequence,\n      maxTimestamp,\n      timestampType\n    };\n    const records = yield decodeRecords(codec, decoder, {\n      ...recordContext,\n      magicByte\n    });\n    return {\n      ...recordContext,\n      records\n    };\n  });\n  return function (_x) {\n    return _ref.apply(this, arguments);\n  };\n}();\nconst decodeRecords = /*#__PURE__*/function () {\n  var _ref2 = _asyncToGenerator(function* (codec, recordsDecoder, recordContext) {\n    if (!codec) {\n      return recordsDecoder.readArray(decoder => decodeRecord(decoder, recordContext));\n    }\n    const length = recordsDecoder.readInt32();\n    if (length <= 0) {\n      return [];\n    }\n    const compressedRecordsBuffer = recordsDecoder.readAll();\n    const decompressedRecordBuffer = yield codec.decompress(compressedRecordsBuffer);\n    const decompressedRecordDecoder = new Decoder(decompressedRecordBuffer);\n    const records = new Array(length);\n    for (let i = 0; i < length; i++) {\n      records[i] = decodeRecord(decompressedRecordDecoder, recordContext);\n    }\n    return records;\n  });\n  return function decodeRecords(_x2, _x3, _x4) {\n    return _ref2.apply(this, arguments);\n  };\n}();\nconst decodeRecord = (decoder, recordContext) => {\n  const recordBuffer = decoder.readVarIntBytes();\n  return RecordDecoder(new Decoder(recordBuffer), recordContext);\n};","map":{"version":3,"names":["Decoder","require","KafkaJSPartialMessageError","lookupCodecByAttributes","RecordDecoder","TimestampTypes","TIMESTAMP_TYPE_FLAG_MASK","TRANSACTIONAL_FLAG_MASK","CONTROL_FLAG_MASK","module","exports","fetchDecoder","firstOffset","readInt64","toString","length","readInt32","decoder","slice","forward","remainingBytes","Buffer","byteLength","buffer","partitionLeaderEpoch","magicByte","readInt8","crc","attributes","readInt16","lastOffsetDelta","firstTimestamp","maxTimestamp","producerId","producerEpoch","firstSequence","inTransaction","isControlBatch","timestampType","LOG_APPEND_TIME","CREATE_TIME","codec","recordContext","records","decodeRecords","recordsDecoder","readArray","decodeRecord","compressedRecordsBuffer","readAll","decompressedRecordBuffer","decompress","decompressedRecordDecoder","Array","i","recordBuffer","readVarIntBytes"],"sources":["C:/Users/ingev/Documents/Desarrollo/Luna/DronController/AD_UI/node_modules/kafkajs/src/protocol/recordBatch/v0/decoder.js"],"sourcesContent":["const Decoder = require('../../decoder')\nconst { KafkaJSPartialMessageError } = require('../../../errors')\nconst { lookupCodecByAttributes } = require('../../message/compression')\nconst RecordDecoder = require('../record/v0/decoder')\nconst TimestampTypes = require('../../timestampTypes')\n\nconst TIMESTAMP_TYPE_FLAG_MASK = 0x8\nconst TRANSACTIONAL_FLAG_MASK = 0x10\nconst CONTROL_FLAG_MASK = 0x20\n\n/**\n * v0\n * RecordBatch =>\n *  FirstOffset => int64\n *  Length => int32\n *  PartitionLeaderEpoch => int32\n *  Magic => int8\n *  CRC => int32\n *  Attributes => int16\n *  LastOffsetDelta => int32\n *  FirstTimestamp => int64\n *  MaxTimestamp => int64\n *  ProducerId => int64\n *  ProducerEpoch => int16\n *  FirstSequence => int32\n *  Records => [Record]\n */\n\nmodule.exports = async fetchDecoder => {\n  const firstOffset = fetchDecoder.readInt64().toString()\n  const length = fetchDecoder.readInt32()\n  const decoder = fetchDecoder.slice(length)\n  fetchDecoder.forward(length)\n\n  const remainingBytes = Buffer.byteLength(decoder.buffer)\n\n  if (remainingBytes < length) {\n    throw new KafkaJSPartialMessageError(\n      `Tried to decode a partial record batch: remainingBytes(${remainingBytes}) < recordBatchLength(${length})`\n    )\n  }\n\n  const partitionLeaderEpoch = decoder.readInt32()\n\n  // The magic byte was read by the Fetch protocol to distinguish between\n  // the record batch and the legacy message set. It's not used here but\n  // it has to be read.\n  const magicByte = decoder.readInt8() // eslint-disable-line no-unused-vars\n\n  // The library is currently not performing CRC validations\n  const crc = decoder.readInt32() // eslint-disable-line no-unused-vars\n\n  const attributes = decoder.readInt16()\n  const lastOffsetDelta = decoder.readInt32()\n  const firstTimestamp = decoder.readInt64().toString()\n  const maxTimestamp = decoder.readInt64().toString()\n  const producerId = decoder.readInt64().toString()\n  const producerEpoch = decoder.readInt16()\n  const firstSequence = decoder.readInt32()\n\n  const inTransaction = (attributes & TRANSACTIONAL_FLAG_MASK) > 0\n  const isControlBatch = (attributes & CONTROL_FLAG_MASK) > 0\n  const timestampType =\n    (attributes & TIMESTAMP_TYPE_FLAG_MASK) > 0\n      ? TimestampTypes.LOG_APPEND_TIME\n      : TimestampTypes.CREATE_TIME\n\n  const codec = lookupCodecByAttributes(attributes)\n\n  const recordContext = {\n    firstOffset,\n    firstTimestamp,\n    partitionLeaderEpoch,\n    inTransaction,\n    isControlBatch,\n    lastOffsetDelta,\n    producerId,\n    producerEpoch,\n    firstSequence,\n    maxTimestamp,\n    timestampType,\n  }\n\n  const records = await decodeRecords(codec, decoder, { ...recordContext, magicByte })\n\n  return {\n    ...recordContext,\n    records,\n  }\n}\n\nconst decodeRecords = async (codec, recordsDecoder, recordContext) => {\n  if (!codec) {\n    return recordsDecoder.readArray(decoder => decodeRecord(decoder, recordContext))\n  }\n\n  const length = recordsDecoder.readInt32()\n\n  if (length <= 0) {\n    return []\n  }\n\n  const compressedRecordsBuffer = recordsDecoder.readAll()\n  const decompressedRecordBuffer = await codec.decompress(compressedRecordsBuffer)\n  const decompressedRecordDecoder = new Decoder(decompressedRecordBuffer)\n  const records = new Array(length)\n\n  for (let i = 0; i < length; i++) {\n    records[i] = decodeRecord(decompressedRecordDecoder, recordContext)\n  }\n\n  return records\n}\n\nconst decodeRecord = (decoder, recordContext) => {\n  const recordBuffer = decoder.readVarIntBytes()\n  return RecordDecoder(new Decoder(recordBuffer), recordContext)\n}\n"],"mappings":";AAAA,MAAMA,OAAO,GAAGC,OAAO,CAAC,eAAe,CAAC;AACxC,MAAM;EAAEC;AAA2B,CAAC,GAAGD,OAAO,CAAC,iBAAiB,CAAC;AACjE,MAAM;EAAEE;AAAwB,CAAC,GAAGF,OAAO,CAAC,2BAA2B,CAAC;AACxE,MAAMG,aAAa,GAAGH,OAAO,CAAC,sBAAsB,CAAC;AACrD,MAAMI,cAAc,GAAGJ,OAAO,CAAC,sBAAsB,CAAC;AAEtD,MAAMK,wBAAwB,GAAG,GAAG;AACpC,MAAMC,uBAAuB,GAAG,IAAI;AACpC,MAAMC,iBAAiB,GAAG,IAAI;;AAE9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEAC,MAAM,CAACC,OAAO;EAAA,6BAAG,WAAMC,YAAY,EAAI;IACrC,MAAMC,WAAW,GAAGD,YAAY,CAACE,SAAS,EAAE,CAACC,QAAQ,EAAE;IACvD,MAAMC,MAAM,GAAGJ,YAAY,CAACK,SAAS,EAAE;IACvC,MAAMC,OAAO,GAAGN,YAAY,CAACO,KAAK,CAACH,MAAM,CAAC;IAC1CJ,YAAY,CAACQ,OAAO,CAACJ,MAAM,CAAC;IAE5B,MAAMK,cAAc,GAAGC,MAAM,CAACC,UAAU,CAACL,OAAO,CAACM,MAAM,CAAC;IAExD,IAAIH,cAAc,GAAGL,MAAM,EAAE;MAC3B,MAAM,IAAIb,0BAA0B,CACjC,0DAAyDkB,cAAe,yBAAwBL,MAAO,GAAE,CAC3G;IACH;IAEA,MAAMS,oBAAoB,GAAGP,OAAO,CAACD,SAAS,EAAE;;IAEhD;IACA;IACA;IACA,MAAMS,SAAS,GAAGR,OAAO,CAACS,QAAQ,EAAE,EAAC;;IAErC;IACA,MAAMC,GAAG,GAAGV,OAAO,CAACD,SAAS,EAAE,EAAC;;IAEhC,MAAMY,UAAU,GAAGX,OAAO,CAACY,SAAS,EAAE;IACtC,MAAMC,eAAe,GAAGb,OAAO,CAACD,SAAS,EAAE;IAC3C,MAAMe,cAAc,GAAGd,OAAO,CAACJ,SAAS,EAAE,CAACC,QAAQ,EAAE;IACrD,MAAMkB,YAAY,GAAGf,OAAO,CAACJ,SAAS,EAAE,CAACC,QAAQ,EAAE;IACnD,MAAMmB,UAAU,GAAGhB,OAAO,CAACJ,SAAS,EAAE,CAACC,QAAQ,EAAE;IACjD,MAAMoB,aAAa,GAAGjB,OAAO,CAACY,SAAS,EAAE;IACzC,MAAMM,aAAa,GAAGlB,OAAO,CAACD,SAAS,EAAE;IAEzC,MAAMoB,aAAa,GAAG,CAACR,UAAU,GAAGrB,uBAAuB,IAAI,CAAC;IAChE,MAAM8B,cAAc,GAAG,CAACT,UAAU,GAAGpB,iBAAiB,IAAI,CAAC;IAC3D,MAAM8B,aAAa,GACjB,CAACV,UAAU,GAAGtB,wBAAwB,IAAI,CAAC,GACvCD,cAAc,CAACkC,eAAe,GAC9BlC,cAAc,CAACmC,WAAW;IAEhC,MAAMC,KAAK,GAAGtC,uBAAuB,CAACyB,UAAU,CAAC;IAEjD,MAAMc,aAAa,GAAG;MACpB9B,WAAW;MACXmB,cAAc;MACdP,oBAAoB;MACpBY,aAAa;MACbC,cAAc;MACdP,eAAe;MACfG,UAAU;MACVC,aAAa;MACbC,aAAa;MACbH,YAAY;MACZM;IACF,CAAC;IAED,MAAMK,OAAO,SAASC,aAAa,CAACH,KAAK,EAAExB,OAAO,EAAE;MAAE,GAAGyB,aAAa;MAAEjB;IAAU,CAAC,CAAC;IAEpF,OAAO;MACL,GAAGiB,aAAa;MAChBC;IACF,CAAC;EACH,CAAC;EAAA;IAAA;EAAA;AAAA;AAED,MAAMC,aAAa;EAAA,8BAAG,WAAOH,KAAK,EAAEI,cAAc,EAAEH,aAAa,EAAK;IACpE,IAAI,CAACD,KAAK,EAAE;MACV,OAAOI,cAAc,CAACC,SAAS,CAAC7B,OAAO,IAAI8B,YAAY,CAAC9B,OAAO,EAAEyB,aAAa,CAAC,CAAC;IAClF;IAEA,MAAM3B,MAAM,GAAG8B,cAAc,CAAC7B,SAAS,EAAE;IAEzC,IAAID,MAAM,IAAI,CAAC,EAAE;MACf,OAAO,EAAE;IACX;IAEA,MAAMiC,uBAAuB,GAAGH,cAAc,CAACI,OAAO,EAAE;IACxD,MAAMC,wBAAwB,SAAST,KAAK,CAACU,UAAU,CAACH,uBAAuB,CAAC;IAChF,MAAMI,yBAAyB,GAAG,IAAIpD,OAAO,CAACkD,wBAAwB,CAAC;IACvE,MAAMP,OAAO,GAAG,IAAIU,KAAK,CAACtC,MAAM,CAAC;IAEjC,KAAK,IAAIuC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGvC,MAAM,EAAEuC,CAAC,EAAE,EAAE;MAC/BX,OAAO,CAACW,CAAC,CAAC,GAAGP,YAAY,CAACK,yBAAyB,EAAEV,aAAa,CAAC;IACrE;IAEA,OAAOC,OAAO;EAChB,CAAC;EAAA,gBArBKC,aAAa;IAAA;EAAA;AAAA,GAqBlB;AAED,MAAMG,YAAY,GAAG,CAAC9B,OAAO,EAAEyB,aAAa,KAAK;EAC/C,MAAMa,YAAY,GAAGtC,OAAO,CAACuC,eAAe,EAAE;EAC9C,OAAOpD,aAAa,CAAC,IAAIJ,OAAO,CAACuD,YAAY,CAAC,EAAEb,aAAa,CAAC;AAChE,CAAC"},"metadata":{},"sourceType":"script","externalDependencies":[]}