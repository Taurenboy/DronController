{"ast":null,"code":"var _asyncToGenerator = require(\"C:/Users/ingev/Documents/Desarrollo/Luna/DronController/AD_UI/node_modules/@babel/runtime/helpers/asyncToGenerator.js\").default;\nconst {\n  EventEmitter\n} = require('events');\nconst Long = require('../utils/long');\nconst createRetry = require('../retry');\nconst {\n  isKafkaJSError,\n  isRebalancing\n} = require('../errors');\nconst {\n  events: {\n    FETCH,\n    FETCH_START,\n    START_BATCH_PROCESS,\n    END_BATCH_PROCESS,\n    REBALANCING\n  }\n} = require('./instrumentationEvents');\nconst createFetchManager = require('./fetchManager');\nconst isSameOffset = (offsetA, offsetB) => Long.fromValue(offsetA).equals(Long.fromValue(offsetB));\nconst CONSUMING_START = 'consuming-start';\nconst CONSUMING_STOP = 'consuming-stop';\nmodule.exports = class Runner extends EventEmitter {\n  /**\n   * @param {object} options\n   * @param {import(\"../../types\").Logger} options.logger\n   * @param {import(\"./consumerGroup\")} options.consumerGroup\n   * @param {import(\"../instrumentation/emitter\")} options.instrumentationEmitter\n   * @param {boolean} [options.eachBatchAutoResolve=true]\n   * @param {number} options.concurrency\n   * @param {(payload: import(\"../../types\").EachBatchPayload) => Promise<void>} [options.eachBatch]\n   * @param {(payload: import(\"../../types\").EachMessagePayload) => Promise<void>} [options.eachMessage]\n   * @param {number} [options.heartbeatInterval]\n   * @param {(reason: Error) => void} options.onCrash\n   * @param {import(\"../../types\").RetryOptions} [options.retry]\n   * @param {boolean} [options.autoCommit=true]\n   */\n  constructor({\n    logger,\n    consumerGroup,\n    instrumentationEmitter,\n    eachBatchAutoResolve = true,\n    concurrency,\n    eachBatch,\n    eachMessage,\n    heartbeatInterval,\n    onCrash,\n    retry,\n    autoCommit = true\n  }) {\n    super();\n    this.logger = logger.namespace('Runner');\n    this.consumerGroup = consumerGroup;\n    this.instrumentationEmitter = instrumentationEmitter;\n    this.eachBatchAutoResolve = eachBatchAutoResolve;\n    this.eachBatch = eachBatch;\n    this.eachMessage = eachMessage;\n    this.heartbeatInterval = heartbeatInterval;\n    this.retrier = createRetry(Object.assign({}, retry));\n    this.onCrash = onCrash;\n    this.autoCommit = autoCommit;\n    this.fetchManager = createFetchManager({\n      logger: this.logger,\n      getNodeIds: () => this.consumerGroup.getNodeIds(),\n      fetch: nodeId => this.fetch(nodeId),\n      handler: batch => this.handleBatch(batch),\n      concurrency\n    });\n    this.running = false;\n    this.consuming = false;\n  }\n  get consuming() {\n    return this._consuming;\n  }\n  set consuming(value) {\n    if (this._consuming !== value) {\n      this._consuming = value;\n      this.emit(value ? CONSUMING_START : CONSUMING_STOP);\n    }\n  }\n  start() {\n    var _this = this;\n    return _asyncToGenerator(function* () {\n      if (_this.running) {\n        return;\n      }\n      try {\n        yield _this.consumerGroup.connect();\n        yield _this.consumerGroup.joinAndSync();\n      } catch (e) {\n        return _this.onCrash(e);\n      }\n      _this.running = true;\n      _this.scheduleFetchManager();\n    })();\n  }\n  scheduleFetchManager() {\n    var _this2 = this;\n    if (!this.running) {\n      this.consuming = false;\n      this.logger.info('consumer not running, exiting', {\n        groupId: this.consumerGroup.groupId,\n        memberId: this.consumerGroup.memberId\n      });\n      return;\n    }\n    this.consuming = true;\n    this.retrier( /*#__PURE__*/function () {\n      var _ref = _asyncToGenerator(function* (bail, retryCount, retryTime) {\n        if (!_this2.running) {\n          return;\n        }\n        try {\n          yield _this2.fetchManager.start();\n        } catch (e) {\n          if (isRebalancing(e)) {\n            _this2.logger.warn('The group is rebalancing, re-joining', {\n              groupId: _this2.consumerGroup.groupId,\n              memberId: _this2.consumerGroup.memberId,\n              error: e.message\n            });\n            _this2.instrumentationEmitter.emit(REBALANCING, {\n              groupId: _this2.consumerGroup.groupId,\n              memberId: _this2.consumerGroup.memberId\n            });\n            yield _this2.consumerGroup.joinAndSync();\n            return;\n          }\n          if (e.type === 'UNKNOWN_MEMBER_ID') {\n            _this2.logger.error('The coordinator is not aware of this member, re-joining the group', {\n              groupId: _this2.consumerGroup.groupId,\n              memberId: _this2.consumerGroup.memberId,\n              error: e.message\n            });\n            _this2.consumerGroup.memberId = null;\n            yield _this2.consumerGroup.joinAndSync();\n            return;\n          }\n          if (e.name === 'KafkaJSNotImplemented') {\n            return bail(e);\n          }\n          if (e.name === 'KafkaJSNoBrokerAvailableError') {\n            return bail(e);\n          }\n          _this2.logger.debug('Error while scheduling fetch manager, trying again...', {\n            groupId: _this2.consumerGroup.groupId,\n            memberId: _this2.consumerGroup.memberId,\n            error: e.message,\n            stack: e.stack,\n            retryCount,\n            retryTime\n          });\n          throw e;\n        }\n      });\n      return function (_x, _x2, _x3) {\n        return _ref.apply(this, arguments);\n      };\n    }()).then(() => {\n      this.scheduleFetchManager();\n    }).catch(e => {\n      this.onCrash(e);\n      this.consuming = false;\n      this.running = false;\n    });\n  }\n  stop() {\n    var _this3 = this;\n    return _asyncToGenerator(function* () {\n      if (!_this3.running) {\n        return;\n      }\n      _this3.logger.debug('stop consumer group', {\n        groupId: _this3.consumerGroup.groupId,\n        memberId: _this3.consumerGroup.memberId\n      });\n      _this3.running = false;\n      try {\n        yield _this3.fetchManager.stop();\n        yield _this3.waitForConsumer();\n        yield _this3.consumerGroup.leave();\n      } catch (e) {}\n    })();\n  }\n  waitForConsumer() {\n    return new Promise(resolve => {\n      if (!this.consuming) {\n        return resolve();\n      }\n      this.logger.debug('waiting for consumer to finish...', {\n        groupId: this.consumerGroup.groupId,\n        memberId: this.consumerGroup.memberId\n      });\n      this.once(CONSUMING_STOP, () => resolve());\n    });\n  }\n  heartbeat() {\n    var _this4 = this;\n    return _asyncToGenerator(function* () {\n      try {\n        yield _this4.consumerGroup.heartbeat({\n          interval: _this4.heartbeatInterval\n        });\n      } catch (e) {\n        if (isRebalancing(e)) {\n          yield _this4.autoCommitOffsets();\n        }\n        throw e;\n      }\n    })();\n  }\n  processEachMessage(batch) {\n    var _this5 = this;\n    return _asyncToGenerator(function* () {\n      const {\n        topic,\n        partition\n      } = batch;\n      const pause = () => {\n        _this5.consumerGroup.pause([{\n          topic,\n          partitions: [partition]\n        }]);\n        return () => _this5.consumerGroup.resume([{\n          topic,\n          partitions: [partition]\n        }]);\n      };\n      for (const message of batch.messages) {\n        if (!_this5.running || _this5.consumerGroup.hasSeekOffset({\n          topic,\n          partition\n        })) {\n          break;\n        }\n        try {\n          yield _this5.eachMessage({\n            topic,\n            partition,\n            message,\n            heartbeat: () => _this5.heartbeat(),\n            pause\n          });\n        } catch (e) {\n          if (!isKafkaJSError(e)) {\n            _this5.logger.error(`Error when calling eachMessage`, {\n              topic,\n              partition,\n              offset: message.offset,\n              stack: e.stack,\n              error: e\n            });\n          }\n\n          // In case of errors, commit the previously consumed offsets unless autoCommit is disabled\n          yield _this5.autoCommitOffsets();\n          throw e;\n        }\n        _this5.consumerGroup.resolveOffset({\n          topic,\n          partition,\n          offset: message.offset\n        });\n        yield _this5.heartbeat();\n        yield _this5.autoCommitOffsetsIfNecessary();\n        if (_this5.consumerGroup.isPaused(topic, partition)) {\n          break;\n        }\n      }\n    })();\n  }\n  processEachBatch(batch) {\n    var _this6 = this;\n    return _asyncToGenerator(function* () {\n      const {\n        topic,\n        partition\n      } = batch;\n      const lastFilteredMessage = batch.messages[batch.messages.length - 1];\n      const pause = () => {\n        _this6.consumerGroup.pause([{\n          topic,\n          partitions: [partition]\n        }]);\n        return () => _this6.consumerGroup.resume([{\n          topic,\n          partitions: [partition]\n        }]);\n      };\n      try {\n        yield _this6.eachBatch({\n          batch,\n          resolveOffset: offset => {\n            /**\n             * The transactional producer generates a control record after committing the transaction.\n             * The control record is the last record on the RecordBatch, and it is filtered before it\n             * reaches the eachBatch callback. When disabling auto-resolve, the user-land code won't\n             * be able to resolve the control record offset, since it never reaches the callback,\n             * causing stuck consumers as the consumer will never move the offset marker.\n             *\n             * When the last offset of the batch is resolved, we should automatically resolve\n             * the control record offset as this entry doesn't have any meaning to the user-land code,\n             * and won't interfere with the stream processing.\n             *\n             * @see https://github.com/apache/kafka/blob/9aa660786e46c1efbf5605a6a69136a1dac6edb9/clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java#L1499-L1505\n             */\n            const offsetToResolve = lastFilteredMessage && isSameOffset(offset, lastFilteredMessage.offset) ? batch.lastOffset() : offset;\n            _this6.consumerGroup.resolveOffset({\n              topic,\n              partition,\n              offset: offsetToResolve\n            });\n          },\n          heartbeat: () => _this6.heartbeat(),\n          /**\n           * Pause consumption for the current topic-partition being processed\n           */\n          pause,\n          /**\n           * Commit offsets if provided. Otherwise commit most recent resolved offsets\n           * if the autoCommit conditions are met.\n           *\n           * @param {import('../../types').OffsetsByTopicPartition} [offsets] Optional.\n           */\n          commitOffsetsIfNecessary: function () {\n            var _ref2 = _asyncToGenerator(function* (offsets) {\n              return offsets ? _this6.consumerGroup.commitOffsets(offsets) : _this6.consumerGroup.commitOffsetsIfNecessary();\n            });\n            return function commitOffsetsIfNecessary(_x4) {\n              return _ref2.apply(this, arguments);\n            };\n          }(),\n          uncommittedOffsets: () => _this6.consumerGroup.uncommittedOffsets(),\n          isRunning: () => _this6.running,\n          isStale: () => _this6.consumerGroup.hasSeekOffset({\n            topic,\n            partition\n          })\n        });\n      } catch (e) {\n        if (!isKafkaJSError(e)) {\n          _this6.logger.error(`Error when calling eachBatch`, {\n            topic,\n            partition,\n            offset: batch.firstOffset(),\n            stack: e.stack,\n            error: e\n          });\n        }\n\n        // eachBatch has a special resolveOffset which can be used\n        // to keep track of the messages\n        yield _this6.autoCommitOffsets();\n        throw e;\n      }\n\n      // resolveOffset for the last offset can be disabled to allow the users of eachBatch to\n      // stop their consumers without resolving unprocessed offsets (issues/18)\n      if (_this6.eachBatchAutoResolve) {\n        _this6.consumerGroup.resolveOffset({\n          topic,\n          partition,\n          offset: batch.lastOffset()\n        });\n      }\n    })();\n  }\n  fetch(nodeId) {\n    var _this7 = this;\n    return _asyncToGenerator(function* () {\n      if (!_this7.running) {\n        _this7.logger.debug('consumer not running, exiting', {\n          groupId: _this7.consumerGroup.groupId,\n          memberId: _this7.consumerGroup.memberId\n        });\n        return [];\n      }\n      const startFetch = Date.now();\n      _this7.instrumentationEmitter.emit(FETCH_START, {\n        nodeId\n      });\n      const batches = yield _this7.consumerGroup.fetch(nodeId);\n      _this7.instrumentationEmitter.emit(FETCH, {\n        /**\n         * PR #570 removed support for the number of batches in this instrumentation event;\n         * The new implementation uses an async generation to deliver the batches, which makes\n         * this number impossible to get. The number is set to 0 to keep the event backward\n         * compatible until we bump KafkaJS to version 2, following the end of node 8 LTS.\n         *\n         * @since 2019-11-29\n         */\n        numberOfBatches: 0,\n        duration: Date.now() - startFetch,\n        nodeId\n      });\n      if (batches.length === 0) {\n        yield _this7.heartbeat();\n      }\n      return batches;\n    })();\n  }\n  handleBatch(batch) {\n    var _this8 = this;\n    return _asyncToGenerator(function* () {\n      if (!_this8.running) {\n        _this8.logger.debug('consumer not running, exiting', {\n          groupId: _this8.consumerGroup.groupId,\n          memberId: _this8.consumerGroup.memberId\n        });\n        return;\n      }\n\n      /** @param {import('./batch')} batch */\n      const onBatch = /*#__PURE__*/function () {\n        var _ref3 = _asyncToGenerator(function* (batch) {\n          const startBatchProcess = Date.now();\n          const payload = {\n            topic: batch.topic,\n            partition: batch.partition,\n            highWatermark: batch.highWatermark,\n            offsetLag: batch.offsetLag(),\n            /**\n             * @since 2019-06-24 (>= 1.8.0)\n             *\n             * offsetLag returns the lag based on the latest offset in the batch, to\n             * keep the event backward compatible we just introduced \"offsetLagLow\"\n             * which calculates the lag based on the first offset in the batch\n             */\n            offsetLagLow: batch.offsetLagLow(),\n            batchSize: batch.messages.length,\n            firstOffset: batch.firstOffset(),\n            lastOffset: batch.lastOffset()\n          };\n\n          /**\n           * If the batch contained only control records or only aborted messages then we still\n           * need to resolve and auto-commit to ensure the consumer can move forward.\n           *\n           * We also need to emit batch instrumentation events to allow any listeners keeping\n           * track of offsets to know about the latest point of consumption.\n           *\n           * Added in #1256\n           *\n           * @see https://github.com/apache/kafka/blob/9aa660786e46c1efbf5605a6a69136a1dac6edb9/clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java#L1499-L1505\n           */\n          if (batch.isEmptyDueToFiltering()) {\n            _this8.instrumentationEmitter.emit(START_BATCH_PROCESS, payload);\n            _this8.consumerGroup.resolveOffset({\n              topic: batch.topic,\n              partition: batch.partition,\n              offset: batch.lastOffset()\n            });\n            yield _this8.autoCommitOffsetsIfNecessary();\n            _this8.instrumentationEmitter.emit(END_BATCH_PROCESS, {\n              ...payload,\n              duration: Date.now() - startBatchProcess\n            });\n            yield _this8.heartbeat();\n            return;\n          }\n          if (batch.isEmpty()) {\n            yield _this8.heartbeat();\n            return;\n          }\n          _this8.instrumentationEmitter.emit(START_BATCH_PROCESS, payload);\n          if (_this8.eachMessage) {\n            yield _this8.processEachMessage(batch);\n          } else if (_this8.eachBatch) {\n            yield _this8.processEachBatch(batch);\n          }\n          _this8.instrumentationEmitter.emit(END_BATCH_PROCESS, {\n            ...payload,\n            duration: Date.now() - startBatchProcess\n          });\n          yield _this8.autoCommitOffsets();\n          yield _this8.heartbeat();\n        });\n        return function onBatch(_x5) {\n          return _ref3.apply(this, arguments);\n        };\n      }();\n      yield onBatch(batch);\n    })();\n  }\n  autoCommitOffsets() {\n    if (this.autoCommit) {\n      return this.consumerGroup.commitOffsets();\n    }\n  }\n  autoCommitOffsetsIfNecessary() {\n    if (this.autoCommit) {\n      return this.consumerGroup.commitOffsetsIfNecessary();\n    }\n  }\n  commitOffsets(offsets) {\n    var _this9 = this;\n    if (!this.running) {\n      this.logger.debug('consumer not running, exiting', {\n        groupId: this.consumerGroup.groupId,\n        memberId: this.consumerGroup.memberId,\n        offsets\n      });\n      return;\n    }\n    return this.retrier( /*#__PURE__*/function () {\n      var _ref4 = _asyncToGenerator(function* (bail, retryCount, retryTime) {\n        try {\n          yield _this9.consumerGroup.commitOffsets(offsets);\n        } catch (e) {\n          if (!_this9.running) {\n            _this9.logger.debug('consumer not running, exiting', {\n              error: e.message,\n              groupId: _this9.consumerGroup.groupId,\n              memberId: _this9.consumerGroup.memberId,\n              offsets\n            });\n            return;\n          }\n          if (e.name === 'KafkaJSNotImplemented') {\n            return bail(e);\n          }\n          _this9.logger.debug('Error while committing offsets, trying again...', {\n            groupId: _this9.consumerGroup.groupId,\n            memberId: _this9.consumerGroup.memberId,\n            error: e.message,\n            stack: e.stack,\n            retryCount,\n            retryTime,\n            offsets\n          });\n          throw e;\n        }\n      });\n      return function (_x6, _x7, _x8) {\n        return _ref4.apply(this, arguments);\n      };\n    }());\n  }\n};","map":{"version":3,"names":["EventEmitter","require","Long","createRetry","isKafkaJSError","isRebalancing","events","FETCH","FETCH_START","START_BATCH_PROCESS","END_BATCH_PROCESS","REBALANCING","createFetchManager","isSameOffset","offsetA","offsetB","fromValue","equals","CONSUMING_START","CONSUMING_STOP","module","exports","Runner","constructor","logger","consumerGroup","instrumentationEmitter","eachBatchAutoResolve","concurrency","eachBatch","eachMessage","heartbeatInterval","onCrash","retry","autoCommit","namespace","retrier","Object","assign","fetchManager","getNodeIds","fetch","nodeId","handler","batch","handleBatch","running","consuming","_consuming","value","emit","start","connect","joinAndSync","e","scheduleFetchManager","info","groupId","memberId","bail","retryCount","retryTime","warn","error","message","type","name","debug","stack","then","catch","stop","waitForConsumer","leave","Promise","resolve","once","heartbeat","interval","autoCommitOffsets","processEachMessage","topic","partition","pause","partitions","resume","messages","hasSeekOffset","offset","resolveOffset","autoCommitOffsetsIfNecessary","isPaused","processEachBatch","lastFilteredMessage","length","offsetToResolve","lastOffset","commitOffsetsIfNecessary","offsets","commitOffsets","uncommittedOffsets","isRunning","isStale","firstOffset","startFetch","Date","now","batches","numberOfBatches","duration","onBatch","startBatchProcess","payload","highWatermark","offsetLag","offsetLagLow","batchSize","isEmptyDueToFiltering","isEmpty"],"sources":["C:/Users/ingev/Documents/Desarrollo/Luna/DronController/AD_UI/node_modules/kafkajs/src/consumer/runner.js"],"sourcesContent":["const { EventEmitter } = require('events')\nconst Long = require('../utils/long')\nconst createRetry = require('../retry')\nconst { isKafkaJSError, isRebalancing } = require('../errors')\n\nconst {\n  events: { FETCH, FETCH_START, START_BATCH_PROCESS, END_BATCH_PROCESS, REBALANCING },\n} = require('./instrumentationEvents')\nconst createFetchManager = require('./fetchManager')\n\nconst isSameOffset = (offsetA, offsetB) => Long.fromValue(offsetA).equals(Long.fromValue(offsetB))\nconst CONSUMING_START = 'consuming-start'\nconst CONSUMING_STOP = 'consuming-stop'\n\nmodule.exports = class Runner extends EventEmitter {\n  /**\n   * @param {object} options\n   * @param {import(\"../../types\").Logger} options.logger\n   * @param {import(\"./consumerGroup\")} options.consumerGroup\n   * @param {import(\"../instrumentation/emitter\")} options.instrumentationEmitter\n   * @param {boolean} [options.eachBatchAutoResolve=true]\n   * @param {number} options.concurrency\n   * @param {(payload: import(\"../../types\").EachBatchPayload) => Promise<void>} [options.eachBatch]\n   * @param {(payload: import(\"../../types\").EachMessagePayload) => Promise<void>} [options.eachMessage]\n   * @param {number} [options.heartbeatInterval]\n   * @param {(reason: Error) => void} options.onCrash\n   * @param {import(\"../../types\").RetryOptions} [options.retry]\n   * @param {boolean} [options.autoCommit=true]\n   */\n  constructor({\n    logger,\n    consumerGroup,\n    instrumentationEmitter,\n    eachBatchAutoResolve = true,\n    concurrency,\n    eachBatch,\n    eachMessage,\n    heartbeatInterval,\n    onCrash,\n    retry,\n    autoCommit = true,\n  }) {\n    super()\n    this.logger = logger.namespace('Runner')\n    this.consumerGroup = consumerGroup\n    this.instrumentationEmitter = instrumentationEmitter\n    this.eachBatchAutoResolve = eachBatchAutoResolve\n    this.eachBatch = eachBatch\n    this.eachMessage = eachMessage\n    this.heartbeatInterval = heartbeatInterval\n    this.retrier = createRetry(Object.assign({}, retry))\n    this.onCrash = onCrash\n    this.autoCommit = autoCommit\n    this.fetchManager = createFetchManager({\n      logger: this.logger,\n      getNodeIds: () => this.consumerGroup.getNodeIds(),\n      fetch: nodeId => this.fetch(nodeId),\n      handler: batch => this.handleBatch(batch),\n      concurrency,\n    })\n\n    this.running = false\n    this.consuming = false\n  }\n\n  get consuming() {\n    return this._consuming\n  }\n\n  set consuming(value) {\n    if (this._consuming !== value) {\n      this._consuming = value\n      this.emit(value ? CONSUMING_START : CONSUMING_STOP)\n    }\n  }\n\n  async start() {\n    if (this.running) {\n      return\n    }\n\n    try {\n      await this.consumerGroup.connect()\n      await this.consumerGroup.joinAndSync()\n    } catch (e) {\n      return this.onCrash(e)\n    }\n\n    this.running = true\n    this.scheduleFetchManager()\n  }\n\n  scheduleFetchManager() {\n    if (!this.running) {\n      this.consuming = false\n\n      this.logger.info('consumer not running, exiting', {\n        groupId: this.consumerGroup.groupId,\n        memberId: this.consumerGroup.memberId,\n      })\n\n      return\n    }\n\n    this.consuming = true\n\n    this.retrier(async (bail, retryCount, retryTime) => {\n      if (!this.running) {\n        return\n      }\n\n      try {\n        await this.fetchManager.start()\n      } catch (e) {\n        if (isRebalancing(e)) {\n          this.logger.warn('The group is rebalancing, re-joining', {\n            groupId: this.consumerGroup.groupId,\n            memberId: this.consumerGroup.memberId,\n            error: e.message,\n          })\n\n          this.instrumentationEmitter.emit(REBALANCING, {\n            groupId: this.consumerGroup.groupId,\n            memberId: this.consumerGroup.memberId,\n          })\n\n          await this.consumerGroup.joinAndSync()\n          return\n        }\n\n        if (e.type === 'UNKNOWN_MEMBER_ID') {\n          this.logger.error('The coordinator is not aware of this member, re-joining the group', {\n            groupId: this.consumerGroup.groupId,\n            memberId: this.consumerGroup.memberId,\n            error: e.message,\n          })\n\n          this.consumerGroup.memberId = null\n          await this.consumerGroup.joinAndSync()\n          return\n        }\n\n        if (e.name === 'KafkaJSNotImplemented') {\n          return bail(e)\n        }\n\n        if (e.name === 'KafkaJSNoBrokerAvailableError') {\n          return bail(e)\n        }\n\n        this.logger.debug('Error while scheduling fetch manager, trying again...', {\n          groupId: this.consumerGroup.groupId,\n          memberId: this.consumerGroup.memberId,\n          error: e.message,\n          stack: e.stack,\n          retryCount,\n          retryTime,\n        })\n\n        throw e\n      }\n    })\n      .then(() => {\n        this.scheduleFetchManager()\n      })\n      .catch(e => {\n        this.onCrash(e)\n        this.consuming = false\n        this.running = false\n      })\n  }\n\n  async stop() {\n    if (!this.running) {\n      return\n    }\n\n    this.logger.debug('stop consumer group', {\n      groupId: this.consumerGroup.groupId,\n      memberId: this.consumerGroup.memberId,\n    })\n\n    this.running = false\n\n    try {\n      await this.fetchManager.stop()\n      await this.waitForConsumer()\n      await this.consumerGroup.leave()\n    } catch (e) {}\n  }\n\n  waitForConsumer() {\n    return new Promise(resolve => {\n      if (!this.consuming) {\n        return resolve()\n      }\n\n      this.logger.debug('waiting for consumer to finish...', {\n        groupId: this.consumerGroup.groupId,\n        memberId: this.consumerGroup.memberId,\n      })\n\n      this.once(CONSUMING_STOP, () => resolve())\n    })\n  }\n\n  async heartbeat() {\n    try {\n      await this.consumerGroup.heartbeat({ interval: this.heartbeatInterval })\n    } catch (e) {\n      if (isRebalancing(e)) {\n        await this.autoCommitOffsets()\n      }\n      throw e\n    }\n  }\n\n  async processEachMessage(batch) {\n    const { topic, partition } = batch\n\n    const pause = () => {\n      this.consumerGroup.pause([{ topic, partitions: [partition] }])\n      return () => this.consumerGroup.resume([{ topic, partitions: [partition] }])\n    }\n    for (const message of batch.messages) {\n      if (!this.running || this.consumerGroup.hasSeekOffset({ topic, partition })) {\n        break\n      }\n\n      try {\n        await this.eachMessage({\n          topic,\n          partition,\n          message,\n          heartbeat: () => this.heartbeat(),\n          pause,\n        })\n      } catch (e) {\n        if (!isKafkaJSError(e)) {\n          this.logger.error(`Error when calling eachMessage`, {\n            topic,\n            partition,\n            offset: message.offset,\n            stack: e.stack,\n            error: e,\n          })\n        }\n\n        // In case of errors, commit the previously consumed offsets unless autoCommit is disabled\n        await this.autoCommitOffsets()\n        throw e\n      }\n\n      this.consumerGroup.resolveOffset({ topic, partition, offset: message.offset })\n      await this.heartbeat()\n      await this.autoCommitOffsetsIfNecessary()\n\n      if (this.consumerGroup.isPaused(topic, partition)) {\n        break\n      }\n    }\n  }\n\n  async processEachBatch(batch) {\n    const { topic, partition } = batch\n    const lastFilteredMessage = batch.messages[batch.messages.length - 1]\n\n    const pause = () => {\n      this.consumerGroup.pause([{ topic, partitions: [partition] }])\n      return () => this.consumerGroup.resume([{ topic, partitions: [partition] }])\n    }\n\n    try {\n      await this.eachBatch({\n        batch,\n        resolveOffset: offset => {\n          /**\n           * The transactional producer generates a control record after committing the transaction.\n           * The control record is the last record on the RecordBatch, and it is filtered before it\n           * reaches the eachBatch callback. When disabling auto-resolve, the user-land code won't\n           * be able to resolve the control record offset, since it never reaches the callback,\n           * causing stuck consumers as the consumer will never move the offset marker.\n           *\n           * When the last offset of the batch is resolved, we should automatically resolve\n           * the control record offset as this entry doesn't have any meaning to the user-land code,\n           * and won't interfere with the stream processing.\n           *\n           * @see https://github.com/apache/kafka/blob/9aa660786e46c1efbf5605a6a69136a1dac6edb9/clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java#L1499-L1505\n           */\n          const offsetToResolve =\n            lastFilteredMessage && isSameOffset(offset, lastFilteredMessage.offset)\n              ? batch.lastOffset()\n              : offset\n\n          this.consumerGroup.resolveOffset({ topic, partition, offset: offsetToResolve })\n        },\n        heartbeat: () => this.heartbeat(),\n        /**\n         * Pause consumption for the current topic-partition being processed\n         */\n        pause,\n        /**\n         * Commit offsets if provided. Otherwise commit most recent resolved offsets\n         * if the autoCommit conditions are met.\n         *\n         * @param {import('../../types').OffsetsByTopicPartition} [offsets] Optional.\n         */\n        commitOffsetsIfNecessary: async offsets => {\n          return offsets\n            ? this.consumerGroup.commitOffsets(offsets)\n            : this.consumerGroup.commitOffsetsIfNecessary()\n        },\n        uncommittedOffsets: () => this.consumerGroup.uncommittedOffsets(),\n        isRunning: () => this.running,\n        isStale: () => this.consumerGroup.hasSeekOffset({ topic, partition }),\n      })\n    } catch (e) {\n      if (!isKafkaJSError(e)) {\n        this.logger.error(`Error when calling eachBatch`, {\n          topic,\n          partition,\n          offset: batch.firstOffset(),\n          stack: e.stack,\n          error: e,\n        })\n      }\n\n      // eachBatch has a special resolveOffset which can be used\n      // to keep track of the messages\n      await this.autoCommitOffsets()\n      throw e\n    }\n\n    // resolveOffset for the last offset can be disabled to allow the users of eachBatch to\n    // stop their consumers without resolving unprocessed offsets (issues/18)\n    if (this.eachBatchAutoResolve) {\n      this.consumerGroup.resolveOffset({ topic, partition, offset: batch.lastOffset() })\n    }\n  }\n\n  async fetch(nodeId) {\n    if (!this.running) {\n      this.logger.debug('consumer not running, exiting', {\n        groupId: this.consumerGroup.groupId,\n        memberId: this.consumerGroup.memberId,\n      })\n\n      return []\n    }\n\n    const startFetch = Date.now()\n\n    this.instrumentationEmitter.emit(FETCH_START, { nodeId })\n\n    const batches = await this.consumerGroup.fetch(nodeId)\n\n    this.instrumentationEmitter.emit(FETCH, {\n      /**\n       * PR #570 removed support for the number of batches in this instrumentation event;\n       * The new implementation uses an async generation to deliver the batches, which makes\n       * this number impossible to get. The number is set to 0 to keep the event backward\n       * compatible until we bump KafkaJS to version 2, following the end of node 8 LTS.\n       *\n       * @since 2019-11-29\n       */\n      numberOfBatches: 0,\n      duration: Date.now() - startFetch,\n      nodeId,\n    })\n\n    if (batches.length === 0) {\n      await this.heartbeat()\n    }\n\n    return batches\n  }\n\n  async handleBatch(batch) {\n    if (!this.running) {\n      this.logger.debug('consumer not running, exiting', {\n        groupId: this.consumerGroup.groupId,\n        memberId: this.consumerGroup.memberId,\n      })\n\n      return\n    }\n\n    /** @param {import('./batch')} batch */\n    const onBatch = async batch => {\n      const startBatchProcess = Date.now()\n      const payload = {\n        topic: batch.topic,\n        partition: batch.partition,\n        highWatermark: batch.highWatermark,\n        offsetLag: batch.offsetLag(),\n        /**\n         * @since 2019-06-24 (>= 1.8.0)\n         *\n         * offsetLag returns the lag based on the latest offset in the batch, to\n         * keep the event backward compatible we just introduced \"offsetLagLow\"\n         * which calculates the lag based on the first offset in the batch\n         */\n        offsetLagLow: batch.offsetLagLow(),\n        batchSize: batch.messages.length,\n        firstOffset: batch.firstOffset(),\n        lastOffset: batch.lastOffset(),\n      }\n\n      /**\n       * If the batch contained only control records or only aborted messages then we still\n       * need to resolve and auto-commit to ensure the consumer can move forward.\n       *\n       * We also need to emit batch instrumentation events to allow any listeners keeping\n       * track of offsets to know about the latest point of consumption.\n       *\n       * Added in #1256\n       *\n       * @see https://github.com/apache/kafka/blob/9aa660786e46c1efbf5605a6a69136a1dac6edb9/clients/src/main/java/org/apache/kafka/clients/consumer/internals/Fetcher.java#L1499-L1505\n       */\n      if (batch.isEmptyDueToFiltering()) {\n        this.instrumentationEmitter.emit(START_BATCH_PROCESS, payload)\n\n        this.consumerGroup.resolveOffset({\n          topic: batch.topic,\n          partition: batch.partition,\n          offset: batch.lastOffset(),\n        })\n        await this.autoCommitOffsetsIfNecessary()\n\n        this.instrumentationEmitter.emit(END_BATCH_PROCESS, {\n          ...payload,\n          duration: Date.now() - startBatchProcess,\n        })\n\n        await this.heartbeat()\n        return\n      }\n\n      if (batch.isEmpty()) {\n        await this.heartbeat()\n        return\n      }\n\n      this.instrumentationEmitter.emit(START_BATCH_PROCESS, payload)\n\n      if (this.eachMessage) {\n        await this.processEachMessage(batch)\n      } else if (this.eachBatch) {\n        await this.processEachBatch(batch)\n      }\n\n      this.instrumentationEmitter.emit(END_BATCH_PROCESS, {\n        ...payload,\n        duration: Date.now() - startBatchProcess,\n      })\n\n      await this.autoCommitOffsets()\n      await this.heartbeat()\n    }\n\n    await onBatch(batch)\n  }\n\n  autoCommitOffsets() {\n    if (this.autoCommit) {\n      return this.consumerGroup.commitOffsets()\n    }\n  }\n\n  autoCommitOffsetsIfNecessary() {\n    if (this.autoCommit) {\n      return this.consumerGroup.commitOffsetsIfNecessary()\n    }\n  }\n\n  commitOffsets(offsets) {\n    if (!this.running) {\n      this.logger.debug('consumer not running, exiting', {\n        groupId: this.consumerGroup.groupId,\n        memberId: this.consumerGroup.memberId,\n        offsets,\n      })\n      return\n    }\n\n    return this.retrier(async (bail, retryCount, retryTime) => {\n      try {\n        await this.consumerGroup.commitOffsets(offsets)\n      } catch (e) {\n        if (!this.running) {\n          this.logger.debug('consumer not running, exiting', {\n            error: e.message,\n            groupId: this.consumerGroup.groupId,\n            memberId: this.consumerGroup.memberId,\n            offsets,\n          })\n          return\n        }\n\n        if (e.name === 'KafkaJSNotImplemented') {\n          return bail(e)\n        }\n\n        this.logger.debug('Error while committing offsets, trying again...', {\n          groupId: this.consumerGroup.groupId,\n          memberId: this.consumerGroup.memberId,\n          error: e.message,\n          stack: e.stack,\n          retryCount,\n          retryTime,\n          offsets,\n        })\n\n        throw e\n      }\n    })\n  }\n}\n"],"mappings":";AAAA,MAAM;EAAEA;AAAa,CAAC,GAAGC,OAAO,CAAC,QAAQ,CAAC;AAC1C,MAAMC,IAAI,GAAGD,OAAO,CAAC,eAAe,CAAC;AACrC,MAAME,WAAW,GAAGF,OAAO,CAAC,UAAU,CAAC;AACvC,MAAM;EAAEG,cAAc;EAAEC;AAAc,CAAC,GAAGJ,OAAO,CAAC,WAAW,CAAC;AAE9D,MAAM;EACJK,MAAM,EAAE;IAAEC,KAAK;IAAEC,WAAW;IAAEC,mBAAmB;IAAEC,iBAAiB;IAAEC;EAAY;AACpF,CAAC,GAAGV,OAAO,CAAC,yBAAyB,CAAC;AACtC,MAAMW,kBAAkB,GAAGX,OAAO,CAAC,gBAAgB,CAAC;AAEpD,MAAMY,YAAY,GAAG,CAACC,OAAO,EAAEC,OAAO,KAAKb,IAAI,CAACc,SAAS,CAACF,OAAO,CAAC,CAACG,MAAM,CAACf,IAAI,CAACc,SAAS,CAACD,OAAO,CAAC,CAAC;AAClG,MAAMG,eAAe,GAAG,iBAAiB;AACzC,MAAMC,cAAc,GAAG,gBAAgB;AAEvCC,MAAM,CAACC,OAAO,GAAG,MAAMC,MAAM,SAAStB,YAAY,CAAC;EACjD;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACEuB,WAAW,CAAC;IACVC,MAAM;IACNC,aAAa;IACbC,sBAAsB;IACtBC,oBAAoB,GAAG,IAAI;IAC3BC,WAAW;IACXC,SAAS;IACTC,WAAW;IACXC,iBAAiB;IACjBC,OAAO;IACPC,KAAK;IACLC,UAAU,GAAG;EACf,CAAC,EAAE;IACD,KAAK,EAAE;IACP,IAAI,CAACV,MAAM,GAAGA,MAAM,CAACW,SAAS,CAAC,QAAQ,CAAC;IACxC,IAAI,CAACV,aAAa,GAAGA,aAAa;IAClC,IAAI,CAACC,sBAAsB,GAAGA,sBAAsB;IACpD,IAAI,CAACC,oBAAoB,GAAGA,oBAAoB;IAChD,IAAI,CAACE,SAAS,GAAGA,SAAS;IAC1B,IAAI,CAACC,WAAW,GAAGA,WAAW;IAC9B,IAAI,CAACC,iBAAiB,GAAGA,iBAAiB;IAC1C,IAAI,CAACK,OAAO,GAAGjC,WAAW,CAACkC,MAAM,CAACC,MAAM,CAAC,CAAC,CAAC,EAAEL,KAAK,CAAC,CAAC;IACpD,IAAI,CAACD,OAAO,GAAGA,OAAO;IACtB,IAAI,CAACE,UAAU,GAAGA,UAAU;IAC5B,IAAI,CAACK,YAAY,GAAG3B,kBAAkB,CAAC;MACrCY,MAAM,EAAE,IAAI,CAACA,MAAM;MACnBgB,UAAU,EAAE,MAAM,IAAI,CAACf,aAAa,CAACe,UAAU,EAAE;MACjDC,KAAK,EAAEC,MAAM,IAAI,IAAI,CAACD,KAAK,CAACC,MAAM,CAAC;MACnCC,OAAO,EAAEC,KAAK,IAAI,IAAI,CAACC,WAAW,CAACD,KAAK,CAAC;MACzChB;IACF,CAAC,CAAC;IAEF,IAAI,CAACkB,OAAO,GAAG,KAAK;IACpB,IAAI,CAACC,SAAS,GAAG,KAAK;EACxB;EAEA,IAAIA,SAAS,GAAG;IACd,OAAO,IAAI,CAACC,UAAU;EACxB;EAEA,IAAID,SAAS,CAACE,KAAK,EAAE;IACnB,IAAI,IAAI,CAACD,UAAU,KAAKC,KAAK,EAAE;MAC7B,IAAI,CAACD,UAAU,GAAGC,KAAK;MACvB,IAAI,CAACC,IAAI,CAACD,KAAK,GAAG/B,eAAe,GAAGC,cAAc,CAAC;IACrD;EACF;EAEMgC,KAAK,GAAG;IAAA;IAAA;MACZ,IAAI,KAAI,CAACL,OAAO,EAAE;QAChB;MACF;MAEA,IAAI;QACF,MAAM,KAAI,CAACrB,aAAa,CAAC2B,OAAO,EAAE;QAClC,MAAM,KAAI,CAAC3B,aAAa,CAAC4B,WAAW,EAAE;MACxC,CAAC,CAAC,OAAOC,CAAC,EAAE;QACV,OAAO,KAAI,CAACtB,OAAO,CAACsB,CAAC,CAAC;MACxB;MAEA,KAAI,CAACR,OAAO,GAAG,IAAI;MACnB,KAAI,CAACS,oBAAoB,EAAE;IAAA;EAC7B;EAEAA,oBAAoB,GAAG;IAAA;IACrB,IAAI,CAAC,IAAI,CAACT,OAAO,EAAE;MACjB,IAAI,CAACC,SAAS,GAAG,KAAK;MAEtB,IAAI,CAACvB,MAAM,CAACgC,IAAI,CAAC,+BAA+B,EAAE;QAChDC,OAAO,EAAE,IAAI,CAAChC,aAAa,CAACgC,OAAO;QACnCC,QAAQ,EAAE,IAAI,CAACjC,aAAa,CAACiC;MAC/B,CAAC,CAAC;MAEF;IACF;IAEA,IAAI,CAACX,SAAS,GAAG,IAAI;IAErB,IAAI,CAACX,OAAO;MAAA,6BAAC,WAAOuB,IAAI,EAAEC,UAAU,EAAEC,SAAS,EAAK;QAClD,IAAI,CAAC,MAAI,CAACf,OAAO,EAAE;UACjB;QACF;QAEA,IAAI;UACF,MAAM,MAAI,CAACP,YAAY,CAACY,KAAK,EAAE;QACjC,CAAC,CAAC,OAAOG,CAAC,EAAE;UACV,IAAIjD,aAAa,CAACiD,CAAC,CAAC,EAAE;YACpB,MAAI,CAAC9B,MAAM,CAACsC,IAAI,CAAC,sCAAsC,EAAE;cACvDL,OAAO,EAAE,MAAI,CAAChC,aAAa,CAACgC,OAAO;cACnCC,QAAQ,EAAE,MAAI,CAACjC,aAAa,CAACiC,QAAQ;cACrCK,KAAK,EAAET,CAAC,CAACU;YACX,CAAC,CAAC;YAEF,MAAI,CAACtC,sBAAsB,CAACwB,IAAI,CAACvC,WAAW,EAAE;cAC5C8C,OAAO,EAAE,MAAI,CAAChC,aAAa,CAACgC,OAAO;cACnCC,QAAQ,EAAE,MAAI,CAACjC,aAAa,CAACiC;YAC/B,CAAC,CAAC;YAEF,MAAM,MAAI,CAACjC,aAAa,CAAC4B,WAAW,EAAE;YACtC;UACF;UAEA,IAAIC,CAAC,CAACW,IAAI,KAAK,mBAAmB,EAAE;YAClC,MAAI,CAACzC,MAAM,CAACuC,KAAK,CAAC,mEAAmE,EAAE;cACrFN,OAAO,EAAE,MAAI,CAAChC,aAAa,CAACgC,OAAO;cACnCC,QAAQ,EAAE,MAAI,CAACjC,aAAa,CAACiC,QAAQ;cACrCK,KAAK,EAAET,CAAC,CAACU;YACX,CAAC,CAAC;YAEF,MAAI,CAACvC,aAAa,CAACiC,QAAQ,GAAG,IAAI;YAClC,MAAM,MAAI,CAACjC,aAAa,CAAC4B,WAAW,EAAE;YACtC;UACF;UAEA,IAAIC,CAAC,CAACY,IAAI,KAAK,uBAAuB,EAAE;YACtC,OAAOP,IAAI,CAACL,CAAC,CAAC;UAChB;UAEA,IAAIA,CAAC,CAACY,IAAI,KAAK,+BAA+B,EAAE;YAC9C,OAAOP,IAAI,CAACL,CAAC,CAAC;UAChB;UAEA,MAAI,CAAC9B,MAAM,CAAC2C,KAAK,CAAC,uDAAuD,EAAE;YACzEV,OAAO,EAAE,MAAI,CAAChC,aAAa,CAACgC,OAAO;YACnCC,QAAQ,EAAE,MAAI,CAACjC,aAAa,CAACiC,QAAQ;YACrCK,KAAK,EAAET,CAAC,CAACU,OAAO;YAChBI,KAAK,EAAEd,CAAC,CAACc,KAAK;YACdR,UAAU;YACVC;UACF,CAAC,CAAC;UAEF,MAAMP,CAAC;QACT;MACF,CAAC;MAAA;QAAA;MAAA;IAAA,IAAC,CACCe,IAAI,CAAC,MAAM;MACV,IAAI,CAACd,oBAAoB,EAAE;IAC7B,CAAC,CAAC,CACDe,KAAK,CAAChB,CAAC,IAAI;MACV,IAAI,CAACtB,OAAO,CAACsB,CAAC,CAAC;MACf,IAAI,CAACP,SAAS,GAAG,KAAK;MACtB,IAAI,CAACD,OAAO,GAAG,KAAK;IACtB,CAAC,CAAC;EACN;EAEMyB,IAAI,GAAG;IAAA;IAAA;MACX,IAAI,CAAC,MAAI,CAACzB,OAAO,EAAE;QACjB;MACF;MAEA,MAAI,CAACtB,MAAM,CAAC2C,KAAK,CAAC,qBAAqB,EAAE;QACvCV,OAAO,EAAE,MAAI,CAAChC,aAAa,CAACgC,OAAO;QACnCC,QAAQ,EAAE,MAAI,CAACjC,aAAa,CAACiC;MAC/B,CAAC,CAAC;MAEF,MAAI,CAACZ,OAAO,GAAG,KAAK;MAEpB,IAAI;QACF,MAAM,MAAI,CAACP,YAAY,CAACgC,IAAI,EAAE;QAC9B,MAAM,MAAI,CAACC,eAAe,EAAE;QAC5B,MAAM,MAAI,CAAC/C,aAAa,CAACgD,KAAK,EAAE;MAClC,CAAC,CAAC,OAAOnB,CAAC,EAAE,CAAC;IAAC;EAChB;EAEAkB,eAAe,GAAG;IAChB,OAAO,IAAIE,OAAO,CAACC,OAAO,IAAI;MAC5B,IAAI,CAAC,IAAI,CAAC5B,SAAS,EAAE;QACnB,OAAO4B,OAAO,EAAE;MAClB;MAEA,IAAI,CAACnD,MAAM,CAAC2C,KAAK,CAAC,mCAAmC,EAAE;QACrDV,OAAO,EAAE,IAAI,CAAChC,aAAa,CAACgC,OAAO;QACnCC,QAAQ,EAAE,IAAI,CAACjC,aAAa,CAACiC;MAC/B,CAAC,CAAC;MAEF,IAAI,CAACkB,IAAI,CAACzD,cAAc,EAAE,MAAMwD,OAAO,EAAE,CAAC;IAC5C,CAAC,CAAC;EACJ;EAEME,SAAS,GAAG;IAAA;IAAA;MAChB,IAAI;QACF,MAAM,MAAI,CAACpD,aAAa,CAACoD,SAAS,CAAC;UAAEC,QAAQ,EAAE,MAAI,CAAC/C;QAAkB,CAAC,CAAC;MAC1E,CAAC,CAAC,OAAOuB,CAAC,EAAE;QACV,IAAIjD,aAAa,CAACiD,CAAC,CAAC,EAAE;UACpB,MAAM,MAAI,CAACyB,iBAAiB,EAAE;QAChC;QACA,MAAMzB,CAAC;MACT;IAAC;EACH;EAEM0B,kBAAkB,CAACpC,KAAK,EAAE;IAAA;IAAA;MAC9B,MAAM;QAAEqC,KAAK;QAAEC;MAAU,CAAC,GAAGtC,KAAK;MAElC,MAAMuC,KAAK,GAAG,MAAM;QAClB,MAAI,CAAC1D,aAAa,CAAC0D,KAAK,CAAC,CAAC;UAAEF,KAAK;UAAEG,UAAU,EAAE,CAACF,SAAS;QAAE,CAAC,CAAC,CAAC;QAC9D,OAAO,MAAM,MAAI,CAACzD,aAAa,CAAC4D,MAAM,CAAC,CAAC;UAAEJ,KAAK;UAAEG,UAAU,EAAE,CAACF,SAAS;QAAE,CAAC,CAAC,CAAC;MAC9E,CAAC;MACD,KAAK,MAAMlB,OAAO,IAAIpB,KAAK,CAAC0C,QAAQ,EAAE;QACpC,IAAI,CAAC,MAAI,CAACxC,OAAO,IAAI,MAAI,CAACrB,aAAa,CAAC8D,aAAa,CAAC;UAAEN,KAAK;UAAEC;QAAU,CAAC,CAAC,EAAE;UAC3E;QACF;QAEA,IAAI;UACF,MAAM,MAAI,CAACpD,WAAW,CAAC;YACrBmD,KAAK;YACLC,SAAS;YACTlB,OAAO;YACPa,SAAS,EAAE,MAAM,MAAI,CAACA,SAAS,EAAE;YACjCM;UACF,CAAC,CAAC;QACJ,CAAC,CAAC,OAAO7B,CAAC,EAAE;UACV,IAAI,CAAClD,cAAc,CAACkD,CAAC,CAAC,EAAE;YACtB,MAAI,CAAC9B,MAAM,CAACuC,KAAK,CAAE,gCAA+B,EAAE;cAClDkB,KAAK;cACLC,SAAS;cACTM,MAAM,EAAExB,OAAO,CAACwB,MAAM;cACtBpB,KAAK,EAAEd,CAAC,CAACc,KAAK;cACdL,KAAK,EAAET;YACT,CAAC,CAAC;UACJ;;UAEA;UACA,MAAM,MAAI,CAACyB,iBAAiB,EAAE;UAC9B,MAAMzB,CAAC;QACT;QAEA,MAAI,CAAC7B,aAAa,CAACgE,aAAa,CAAC;UAAER,KAAK;UAAEC,SAAS;UAAEM,MAAM,EAAExB,OAAO,CAACwB;QAAO,CAAC,CAAC;QAC9E,MAAM,MAAI,CAACX,SAAS,EAAE;QACtB,MAAM,MAAI,CAACa,4BAA4B,EAAE;QAEzC,IAAI,MAAI,CAACjE,aAAa,CAACkE,QAAQ,CAACV,KAAK,EAAEC,SAAS,CAAC,EAAE;UACjD;QACF;MACF;IAAC;EACH;EAEMU,gBAAgB,CAAChD,KAAK,EAAE;IAAA;IAAA;MAC5B,MAAM;QAAEqC,KAAK;QAAEC;MAAU,CAAC,GAAGtC,KAAK;MAClC,MAAMiD,mBAAmB,GAAGjD,KAAK,CAAC0C,QAAQ,CAAC1C,KAAK,CAAC0C,QAAQ,CAACQ,MAAM,GAAG,CAAC,CAAC;MAErE,MAAMX,KAAK,GAAG,MAAM;QAClB,MAAI,CAAC1D,aAAa,CAAC0D,KAAK,CAAC,CAAC;UAAEF,KAAK;UAAEG,UAAU,EAAE,CAACF,SAAS;QAAE,CAAC,CAAC,CAAC;QAC9D,OAAO,MAAM,MAAI,CAACzD,aAAa,CAAC4D,MAAM,CAAC,CAAC;UAAEJ,KAAK;UAAEG,UAAU,EAAE,CAACF,SAAS;QAAE,CAAC,CAAC,CAAC;MAC9E,CAAC;MAED,IAAI;QACF,MAAM,MAAI,CAACrD,SAAS,CAAC;UACnBe,KAAK;UACL6C,aAAa,EAAED,MAAM,IAAI;YACvB;AACV;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;YACU,MAAMO,eAAe,GACnBF,mBAAmB,IAAIhF,YAAY,CAAC2E,MAAM,EAAEK,mBAAmB,CAACL,MAAM,CAAC,GACnE5C,KAAK,CAACoD,UAAU,EAAE,GAClBR,MAAM;YAEZ,MAAI,CAAC/D,aAAa,CAACgE,aAAa,CAAC;cAAER,KAAK;cAAEC,SAAS;cAAEM,MAAM,EAAEO;YAAgB,CAAC,CAAC;UACjF,CAAC;UACDlB,SAAS,EAAE,MAAM,MAAI,CAACA,SAAS,EAAE;UACjC;AACR;AACA;UACQM,KAAK;UACL;AACR;AACA;AACA;AACA;AACA;UACQc,wBAAwB;YAAA,8BAAE,WAAMC,OAAO,EAAI;cACzC,OAAOA,OAAO,GACV,MAAI,CAACzE,aAAa,CAAC0E,aAAa,CAACD,OAAO,CAAC,GACzC,MAAI,CAACzE,aAAa,CAACwE,wBAAwB,EAAE;YACnD,CAAC;YAAA;cAAA;YAAA;UAAA;UACDG,kBAAkB,EAAE,MAAM,MAAI,CAAC3E,aAAa,CAAC2E,kBAAkB,EAAE;UACjEC,SAAS,EAAE,MAAM,MAAI,CAACvD,OAAO;UAC7BwD,OAAO,EAAE,MAAM,MAAI,CAAC7E,aAAa,CAAC8D,aAAa,CAAC;YAAEN,KAAK;YAAEC;UAAU,CAAC;QACtE,CAAC,CAAC;MACJ,CAAC,CAAC,OAAO5B,CAAC,EAAE;QACV,IAAI,CAAClD,cAAc,CAACkD,CAAC,CAAC,EAAE;UACtB,MAAI,CAAC9B,MAAM,CAACuC,KAAK,CAAE,8BAA6B,EAAE;YAChDkB,KAAK;YACLC,SAAS;YACTM,MAAM,EAAE5C,KAAK,CAAC2D,WAAW,EAAE;YAC3BnC,KAAK,EAAEd,CAAC,CAACc,KAAK;YACdL,KAAK,EAAET;UACT,CAAC,CAAC;QACJ;;QAEA;QACA;QACA,MAAM,MAAI,CAACyB,iBAAiB,EAAE;QAC9B,MAAMzB,CAAC;MACT;;MAEA;MACA;MACA,IAAI,MAAI,CAAC3B,oBAAoB,EAAE;QAC7B,MAAI,CAACF,aAAa,CAACgE,aAAa,CAAC;UAAER,KAAK;UAAEC,SAAS;UAAEM,MAAM,EAAE5C,KAAK,CAACoD,UAAU;QAAG,CAAC,CAAC;MACpF;IAAC;EACH;EAEMvD,KAAK,CAACC,MAAM,EAAE;IAAA;IAAA;MAClB,IAAI,CAAC,MAAI,CAACI,OAAO,EAAE;QACjB,MAAI,CAACtB,MAAM,CAAC2C,KAAK,CAAC,+BAA+B,EAAE;UACjDV,OAAO,EAAE,MAAI,CAAChC,aAAa,CAACgC,OAAO;UACnCC,QAAQ,EAAE,MAAI,CAACjC,aAAa,CAACiC;QAC/B,CAAC,CAAC;QAEF,OAAO,EAAE;MACX;MAEA,MAAM8C,UAAU,GAAGC,IAAI,CAACC,GAAG,EAAE;MAE7B,MAAI,CAAChF,sBAAsB,CAACwB,IAAI,CAAC1C,WAAW,EAAE;QAAEkC;MAAO,CAAC,CAAC;MAEzD,MAAMiE,OAAO,SAAS,MAAI,CAAClF,aAAa,CAACgB,KAAK,CAACC,MAAM,CAAC;MAEtD,MAAI,CAAChB,sBAAsB,CAACwB,IAAI,CAAC3C,KAAK,EAAE;QACtC;AACN;AACA;AACA;AACA;AACA;AACA;AACA;QACMqG,eAAe,EAAE,CAAC;QAClBC,QAAQ,EAAEJ,IAAI,CAACC,GAAG,EAAE,GAAGF,UAAU;QACjC9D;MACF,CAAC,CAAC;MAEF,IAAIiE,OAAO,CAACb,MAAM,KAAK,CAAC,EAAE;QACxB,MAAM,MAAI,CAACjB,SAAS,EAAE;MACxB;MAEA,OAAO8B,OAAO;IAAA;EAChB;EAEM9D,WAAW,CAACD,KAAK,EAAE;IAAA;IAAA;MACvB,IAAI,CAAC,MAAI,CAACE,OAAO,EAAE;QACjB,MAAI,CAACtB,MAAM,CAAC2C,KAAK,CAAC,+BAA+B,EAAE;UACjDV,OAAO,EAAE,MAAI,CAAChC,aAAa,CAACgC,OAAO;UACnCC,QAAQ,EAAE,MAAI,CAACjC,aAAa,CAACiC;QAC/B,CAAC,CAAC;QAEF;MACF;;MAEA;MACA,MAAMoD,OAAO;QAAA,8BAAG,WAAMlE,KAAK,EAAI;UAC7B,MAAMmE,iBAAiB,GAAGN,IAAI,CAACC,GAAG,EAAE;UACpC,MAAMM,OAAO,GAAG;YACd/B,KAAK,EAAErC,KAAK,CAACqC,KAAK;YAClBC,SAAS,EAAEtC,KAAK,CAACsC,SAAS;YAC1B+B,aAAa,EAAErE,KAAK,CAACqE,aAAa;YAClCC,SAAS,EAAEtE,KAAK,CAACsE,SAAS,EAAE;YAC5B;AACR;AACA;AACA;AACA;AACA;AACA;YACQC,YAAY,EAAEvE,KAAK,CAACuE,YAAY,EAAE;YAClCC,SAAS,EAAExE,KAAK,CAAC0C,QAAQ,CAACQ,MAAM;YAChCS,WAAW,EAAE3D,KAAK,CAAC2D,WAAW,EAAE;YAChCP,UAAU,EAAEpD,KAAK,CAACoD,UAAU;UAC9B,CAAC;;UAED;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;UACM,IAAIpD,KAAK,CAACyE,qBAAqB,EAAE,EAAE;YACjC,MAAI,CAAC3F,sBAAsB,CAACwB,IAAI,CAACzC,mBAAmB,EAAEuG,OAAO,CAAC;YAE9D,MAAI,CAACvF,aAAa,CAACgE,aAAa,CAAC;cAC/BR,KAAK,EAAErC,KAAK,CAACqC,KAAK;cAClBC,SAAS,EAAEtC,KAAK,CAACsC,SAAS;cAC1BM,MAAM,EAAE5C,KAAK,CAACoD,UAAU;YAC1B,CAAC,CAAC;YACF,MAAM,MAAI,CAACN,4BAA4B,EAAE;YAEzC,MAAI,CAAChE,sBAAsB,CAACwB,IAAI,CAACxC,iBAAiB,EAAE;cAClD,GAAGsG,OAAO;cACVH,QAAQ,EAAEJ,IAAI,CAACC,GAAG,EAAE,GAAGK;YACzB,CAAC,CAAC;YAEF,MAAM,MAAI,CAAClC,SAAS,EAAE;YACtB;UACF;UAEA,IAAIjC,KAAK,CAAC0E,OAAO,EAAE,EAAE;YACnB,MAAM,MAAI,CAACzC,SAAS,EAAE;YACtB;UACF;UAEA,MAAI,CAACnD,sBAAsB,CAACwB,IAAI,CAACzC,mBAAmB,EAAEuG,OAAO,CAAC;UAE9D,IAAI,MAAI,CAAClF,WAAW,EAAE;YACpB,MAAM,MAAI,CAACkD,kBAAkB,CAACpC,KAAK,CAAC;UACtC,CAAC,MAAM,IAAI,MAAI,CAACf,SAAS,EAAE;YACzB,MAAM,MAAI,CAAC+D,gBAAgB,CAAChD,KAAK,CAAC;UACpC;UAEA,MAAI,CAAClB,sBAAsB,CAACwB,IAAI,CAACxC,iBAAiB,EAAE;YAClD,GAAGsG,OAAO;YACVH,QAAQ,EAAEJ,IAAI,CAACC,GAAG,EAAE,GAAGK;UACzB,CAAC,CAAC;UAEF,MAAM,MAAI,CAAChC,iBAAiB,EAAE;UAC9B,MAAM,MAAI,CAACF,SAAS,EAAE;QACxB,CAAC;QAAA,gBAtEKiC,OAAO;UAAA;QAAA;MAAA,GAsEZ;MAED,MAAMA,OAAO,CAAClE,KAAK,CAAC;IAAA;EACtB;EAEAmC,iBAAiB,GAAG;IAClB,IAAI,IAAI,CAAC7C,UAAU,EAAE;MACnB,OAAO,IAAI,CAACT,aAAa,CAAC0E,aAAa,EAAE;IAC3C;EACF;EAEAT,4BAA4B,GAAG;IAC7B,IAAI,IAAI,CAACxD,UAAU,EAAE;MACnB,OAAO,IAAI,CAACT,aAAa,CAACwE,wBAAwB,EAAE;IACtD;EACF;EAEAE,aAAa,CAACD,OAAO,EAAE;IAAA;IACrB,IAAI,CAAC,IAAI,CAACpD,OAAO,EAAE;MACjB,IAAI,CAACtB,MAAM,CAAC2C,KAAK,CAAC,+BAA+B,EAAE;QACjDV,OAAO,EAAE,IAAI,CAAChC,aAAa,CAACgC,OAAO;QACnCC,QAAQ,EAAE,IAAI,CAACjC,aAAa,CAACiC,QAAQ;QACrCwC;MACF,CAAC,CAAC;MACF;IACF;IAEA,OAAO,IAAI,CAAC9D,OAAO;MAAA,8BAAC,WAAOuB,IAAI,EAAEC,UAAU,EAAEC,SAAS,EAAK;QACzD,IAAI;UACF,MAAM,MAAI,CAACpC,aAAa,CAAC0E,aAAa,CAACD,OAAO,CAAC;QACjD,CAAC,CAAC,OAAO5C,CAAC,EAAE;UACV,IAAI,CAAC,MAAI,CAACR,OAAO,EAAE;YACjB,MAAI,CAACtB,MAAM,CAAC2C,KAAK,CAAC,+BAA+B,EAAE;cACjDJ,KAAK,EAAET,CAAC,CAACU,OAAO;cAChBP,OAAO,EAAE,MAAI,CAAChC,aAAa,CAACgC,OAAO;cACnCC,QAAQ,EAAE,MAAI,CAACjC,aAAa,CAACiC,QAAQ;cACrCwC;YACF,CAAC,CAAC;YACF;UACF;UAEA,IAAI5C,CAAC,CAACY,IAAI,KAAK,uBAAuB,EAAE;YACtC,OAAOP,IAAI,CAACL,CAAC,CAAC;UAChB;UAEA,MAAI,CAAC9B,MAAM,CAAC2C,KAAK,CAAC,iDAAiD,EAAE;YACnEV,OAAO,EAAE,MAAI,CAAChC,aAAa,CAACgC,OAAO;YACnCC,QAAQ,EAAE,MAAI,CAACjC,aAAa,CAACiC,QAAQ;YACrCK,KAAK,EAAET,CAAC,CAACU,OAAO;YAChBI,KAAK,EAAEd,CAAC,CAACc,KAAK;YACdR,UAAU;YACVC,SAAS;YACTqC;UACF,CAAC,CAAC;UAEF,MAAM5C,CAAC;QACT;MACF,CAAC;MAAA;QAAA;MAAA;IAAA,IAAC;EACJ;AACF,CAAC"},"metadata":{},"sourceType":"script","externalDependencies":[]}